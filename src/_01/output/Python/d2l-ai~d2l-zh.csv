Unnamed: 0|path|owner|project|file|language|code|comment|blank
0|./src/_00/output/Python/d2l-ai~d2l-zh/img/twogpu.svg|d2l-ai|d2l-zh|twogpu.svg|SVG|2983|0|0
1|./src/_00/output/Python/d2l-ai~d2l-zh/d2l/paddle.py|d2l-ai|d2l-zh|paddle.py|Python|1851|457|372
2|./src/_00/output/Python/d2l-ai~d2l-zh/d2l/torch.py|d2l-ai|d2l-zh|torch.py|Python|1844|450|372
3|./src/_00/output/Python/d2l-ai~d2l-zh/d2l.bib|d2l-ai|d2l-zh|d2l.bib|TeX|1755|0|197
4|./src/_00/output/Python/d2l-ai~d2l-zh/d2l/mxnet.py|d2l-ai|d2l-zh|mxnet.py|Python|1742|441|368
5|./src/_00/output/Python/d2l-ai~d2l-zh/img/splitting.svg|d2l-ai|d2l-zh|splitting.svg|SVG|1469|0|0
6|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_introduction/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|1458|0|173
7|./src/_00/output/Python/d2l-ai~d2l-zh/img/nvlink-twoloop.svg|d2l-ai|d2l-zh|nvlink-twoloop.svg|SVG|1134|0|0
8|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/transformer.md|d2l-ai|d2l-zh|transformer.md|Markdown|1010|0|151
9|./src/_00/output/Python/d2l-ai~d2l-zh/img/skylake.svg|d2l-ai|d2l-zh|skylake.svg|SVG|1004|0|0
10|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/seq2seq.md|d2l-ai|d2l-zh|seq2seq.md|Markdown|999|0|124
11|./src/_00/output/Python/d2l-ai~d2l-zh/d2l/tensorflow.py|d2l-ai|d2l-zh|tensorflow.py|Python|994|256|227
12|./src/_00/output/Python/d2l-ai~d2l-zh/img/vgg.svg|d2l-ai|d2l-zh|vgg.svg|SVG|948|0|0
13|./src/_00/output/Python/d2l-ai~d2l-zh/img/alexnet.svg|d2l-ai|d2l-zh|alexnet.svg|SVG|946|0|0
14|./src/_00/output/Python/d2l-ai~d2l-zh/img/textcnn.svg|d2l-ai|d2l-zh|textcnn.svg|SVG|938|0|0
15|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/anchor.md|d2l-ai|d2l-zh|anchor.md|Markdown|893|0|126
16|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/rnn-scratch.md|d2l-ai|d2l-zh|rnn-scratch.md|Markdown|889|0|119
17|./src/_00/output/Python/d2l-ai~d2l-zh/img/nin.svg|d2l-ai|d2l-zh|nin.svg|SVG|876|0|0
18|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/linear-algebra.md|d2l-ai|d2l-zh|linear-algebra.md|Markdown|873|0|238
19|./src/_00/output/Python/d2l-ai~d2l-zh/static/frontpage/frontpage.html|d2l-ai|d2l-zh|frontpage.html|HTML|871|455|43
20|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/linear-algebra_origin.md|d2l-ai|d2l-zh|linear-algebra_origin.md|Markdown|869|0|225
21|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/ssd_origin.md|d2l-ai|d2l-zh|ssd_origin.md|Markdown|819|0|138
22|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/ssd.md|d2l-ai|d2l-zh|ssd.md|Markdown|818|0|160
23|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/anchor_origin.md|d2l-ai|d2l-zh|anchor_origin.md|Markdown|802|0|107
24|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/transformer_origin.md|d2l-ai|d2l-zh|transformer_origin.md|Markdown|778|0|107
25|./src/_00/output/Python/d2l-ai~d2l-zh/img/ringsync.svg|d2l-ai|d2l-zh|ringsync.svg|SVG|763|0|0
26|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/seq2seq_origin.md|d2l-ai|d2l-zh|seq2seq_origin.md|Markdown|737|0|92
27|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/rnn-scratch_origin.md|d2l-ai|d2l-zh|rnn-scratch_origin.md|Markdown|726|0|105
28|./src/_00/output/Python/d2l-ai~d2l-zh/img/ps-multimachine.svg|d2l-ai|d2l-zh|ps-multimachine.svg|SVG|719|0|0
29|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/minibatch-sgd.md|d2l-ai|d2l-zh|minibatch-sgd.md|Markdown|685|0|107
30|./src/_00/output/Python/d2l-ai~d2l-zh/img/nvlink.svg|d2l-ai|d2l-zh|nvlink.svg|SVG|681|0|0
31|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/model-construction_origin.md|d2l-ai|d2l-zh|model-construction_origin.md|Markdown|646|0|89
32|./src/_00/output/Python/d2l-ai~d2l-zh/img/bert-input.svg|d2l-ai|d2l-zh|bert-input.svg|SVG|644|0|0
33|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/d2lzh/utils.py|d2l-ai|d2l-zh|utils.py|Python|641|54|142
34|./src/_00/output/Python/d2l-ai~d2l-zh/img/alexnet-original.svg|d2l-ai|d2l-zh|alexnet-original.svg|SVG|633|0|0
35|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/batch-norm_origin.md|d2l-ai|d2l-zh|batch-norm_origin.md|Markdown|628|0|84
36|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/model-construction.md|d2l-ai|d2l-zh|model-construction.md|Markdown|613|0|110
37|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/parameters.md|d2l-ai|d2l-zh|parameters.md|Markdown|609|0|130
38|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/kaggle-house-price_origin.md|d2l-ai|d2l-zh|kaggle-house-price_origin.md|Markdown|607|0|92
39|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/nadaraya-waston.md|d2l-ai|d2l-zh|nadaraya-waston.md|Markdown|588|0|115
40|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/kaggle-cifar10.md|d2l-ai|d2l-zh|kaggle-cifar10.md|Markdown|582|0|104
41|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/ndarray_origin.md|d2l-ai|d2l-zh|ndarray_origin.md|Markdown|580|0|130
42|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_introduction/index.md|d2l-ai|d2l-zh|index.md|Markdown|579|0|169
43|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/parameters_origin.md|d2l-ai|d2l-zh|parameters_origin.md|Markdown|569|0|114
44|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/environment_origin.md|d2l-ai|d2l-zh|environment_origin.md|Markdown|560|0|136
45|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/underfit-overfit_origin.md|d2l-ai|d2l-zh|underfit-overfit_origin.md|Markdown|560|0|92
46|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/lr-scheduler.md|d2l-ai|d2l-zh|lr-scheduler.md|Markdown|551|0|112
47|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/ndarray.md|d2l-ai|d2l-zh|ndarray.md|Markdown|548|0|135
48|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/linear-regression_origin.md|d2l-ai|d2l-zh|linear-regression_origin.md|Markdown|545|0|122
49|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/kaggle-house-price.md|d2l-ai|d2l-zh|kaggle-house-price.md|Markdown|539|0|93
50|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/softmax-regression-scratch.md|d2l-ai|d2l-zh|softmax-regression-scratch.md|Markdown|537|0|98
51|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/kaggle-dog.md|d2l-ai|d2l-zh|kaggle-dog.md|Markdown|536|0|88
52|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/batch-norm.md|d2l-ai|d2l-zh|batch-norm.md|Markdown|531|0|85
53|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/bert_origin.md|d2l-ai|d2l-zh|bert_origin.md|Markdown|530|0|84
54|./src/_00/output/Python/d2l-ai~d2l-zh/img/blocks.svg|d2l-ai|d2l-zh|blocks.svg|SVG|514|0|0
55|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/softmax-regression-scratch_origin.md|d2l-ai|d2l-zh|softmax-regression-scratch_origin.md|Markdown|511|0|86
56|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/attention-scoring-functions.md|d2l-ai|d2l-zh|attention-scoring-functions.md|Markdown|508|0|81
57|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/kaggle-cifar10_origin.md|d2l-ai|d2l-zh|kaggle-cifar10_origin.md|Markdown|501|0|87
58|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/minibatch-sgd_origin.md|d2l-ai|d2l-zh|minibatch-sgd_origin.md|Markdown|499|0|93
59|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/multiple-gpus.md|d2l-ai|d2l-zh|multiple-gpus.md|Markdown|496|0|80
60|./src/_00/output/Python/d2l-ai~d2l-zh/img/inception-full.svg|d2l-ai|d2l-zh|inception-full.svg|SVG|490|0|0
61|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/weight-decay_origin.md|d2l-ai|d2l-zh|weight-decay_origin.md|Markdown|489|0|73
62|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/bert.md|d2l-ai|d2l-zh|bert.md|Markdown|489|0|93
63|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/dropout_origin.md|d2l-ai|d2l-zh|dropout_origin.md|Markdown|484|0|82
64|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/mlp_origin.md|d2l-ai|d2l-zh|mlp_origin.md|Markdown|484|0|95
65|./src/_00/output/Python/d2l-ai~d2l-zh/img/rec-deepfm.svg|d2l-ai|d2l-zh|rec-deepfm.svg|SVG|477|0|0
66|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/underfit-overfit.md|d2l-ai|d2l-zh|underfit-overfit.md|Markdown|474|0|90
67|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/semantic-segmentation-and-dataset.md|d2l-ai|d2l-zh|semantic-segmentation-and-dataset.md|Markdown|473|0|85
68|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/sequence.md|d2l-ai|d2l-zh|sequence.md|Markdown|471|0|87
69|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/image-augmentation.md|d2l-ai|d2l-zh|image-augmentation.md|Markdown|468|0|88
70|./src/_00/output/Python/d2l-ai~d2l-zh/img/nli_attention.svg|d2l-ai|d2l-zh|nli_attention.svg|SVG|466|0|0
71|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/neural-style_origin.md|d2l-ai|d2l-zh|neural-style_origin.md|Markdown|463|0|96
72|./src/_00/output/Python/d2l-ai~d2l-zh/img/lenet.svg|d2l-ai|d2l-zh|lenet.svg|SVG|462|0|0
73|./src/_00/output/Python/d2l-ai~d2l-zh/img/ps-distributed.svg|d2l-ai|d2l-zh|ps-distributed.svg|SVG|462|0|0
74|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/weight-decay.md|d2l-ai|d2l-zh|weight-decay.md|Markdown|461|0|71
75|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/neural-style.md|d2l-ai|d2l-zh|neural-style.md|Markdown|459|0|104
76|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/dropout.md|d2l-ai|d2l-zh|dropout.md|Markdown|457|0|92
77|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/natural-language-inference-attention.md|d2l-ai|d2l-zh|natural-language-inference-attention.md|Markdown|456|0|98
78|./src/_00/output/Python/d2l-ai~d2l-zh/img/nin-compare.svg|d2l-ai|d2l-zh|nin-compare.svg|SVG|455|0|0
79|./src/_00/output/Python/d2l-ai~d2l-zh/img/seq2seq-attention.svg|d2l-ai|d2l-zh|seq2seq-attention.svg|SVG|446|0|0
80|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/kaggle-dog_origin.md|d2l-ai|d2l-zh|kaggle-dog_origin.md|Markdown|442|0|76
81|./src/_00/output/Python/d2l-ai~d2l-zh/img/lstm-3.svg|d2l-ai|d2l-zh|lstm-3.svg|SVG|440|0|0
82|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/linear-regression-concise.md|d2l-ai|d2l-zh|linear-regression-concise.md|Markdown|434|0|89
83|./src/_00/output/Python/d2l-ai~d2l-zh/img/statistical-significance.svg|d2l-ai|d2l-zh|statistical-significance.svg|SVG|434|0|0
84|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/alexnet_origin.md|d2l-ai|d2l-zh|alexnet_origin.md|Markdown|431|0|59
85|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/use-gpu_origin.md|d2l-ai|d2l-zh|use-gpu_origin.md|Markdown|431|0|91
86|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/linear-regression-concise_origin.md|d2l-ai|d2l-zh|linear-regression-concise_origin.md|Markdown|431|0|78
87|./src/_00/output/Python/d2l-ai~d2l-zh/img/falsesharing.svg|d2l-ai|d2l-zh|falsesharing.svg|SVG|430|0|0
88|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/resnet.md|d2l-ai|d2l-zh|resnet.md|Markdown|429|0|76
89|./src/_00/output/Python/d2l-ai~d2l-zh/img/ps-multips.svg|d2l-ai|d2l-zh|ps-multips.svg|SVG|429|0|0
90|./src/_00/output/Python/d2l-ai~d2l-zh/img/book-org.svg|d2l-ai|d2l-zh|book-org.svg|SVG|428|0|0
91|./src/_00/output/Python/d2l-ai~d2l-zh/img/gru-3.svg|d2l-ai|d2l-zh|gru-3.svg|SVG|427|0|0
92|./src/_00/output/Python/d2l-ai~d2l-zh/img/elmo-gpt-bert.svg|d2l-ai|d2l-zh|elmo-gpt-bert.svg|SVG|426|0|0
93|./src/_00/output/Python/d2l-ai~d2l-zh/img/transformer.svg|d2l-ai|d2l-zh|transformer.svg|SVG|426|0|0
94|./src/_00/output/Python/d2l-ai~d2l-zh/img/bert-tagging.svg|d2l-ai|d2l-zh|bert-tagging.svg|SVG|425|0|0
95|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/gru.md|d2l-ai|d2l-zh|gru.md|Markdown|422|0|87
96|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/use-gpu.md|d2l-ai|d2l-zh|use-gpu.md|Markdown|420|0|100
97|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/lstm.md|d2l-ai|d2l-zh|lstm.md|Markdown|419|0|85
98|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/word-embedding-dataset_origin.md|d2l-ai|d2l-zh|word-embedding-dataset_origin.md|Markdown|416|0|79
99|./src/_00/output/Python/d2l-ai~d2l-zh/img/lstm-2.svg|d2l-ai|d2l-zh|lstm-2.svg|SVG|412|0|0
100|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/probability.md|d2l-ai|d2l-zh|probability.md|Markdown|411|0|103
101|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/linear-regression.md|d2l-ai|d2l-zh|linear-regression.md|Markdown|410|0|114
102|./src/_00/output/Python/d2l-ai~d2l-zh/img/lenet-vert.svg|d2l-ai|d2l-zh|lenet-vert.svg|SVG|409|0|0
103|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/fcn.md|d2l-ai|d2l-zh|fcn.md|Markdown|408|0|80
104|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/lenet_origin.md|d2l-ai|d2l-zh|lenet_origin.md|Markdown|406|0|49
105|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/conv-layer_origin.md|d2l-ai|d2l-zh|conv-layer_origin.md|Markdown|405|0|77
106|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/lr-scheduler_origin.md|d2l-ai|d2l-zh|lr-scheduler_origin.md|Markdown|405|0|95
107|./src/_00/output/Python/d2l-ai~d2l-zh/img/bert-qa.svg|d2l-ai|d2l-zh|bert-qa.svg|SVG|404|0|0
108|./src/_00/output/Python/d2l-ai~d2l-zh/img/conv-pad.svg|d2l-ai|d2l-zh|conv-pad.svg|SVG|403|0|0
109|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/bahdanau-attention.md|d2l-ai|d2l-zh|bahdanau-attention.md|Markdown|401|0|60
110|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/densenet.md|d2l-ai|d2l-zh|densenet.md|Markdown|401|0|80
111|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/lenet.md|d2l-ai|d2l-zh|lenet.md|Markdown|401|0|54
112|./src/_00/output/Python/d2l-ai~d2l-zh/img/conv-multi-in.svg|d2l-ai|d2l-zh|conv-multi-in.svg|SVG|401|0|0
113|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/mlp.md|d2l-ai|d2l-zh|mlp.md|Markdown|398|0|89
114|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/natural-language-inference-bert.md|d2l-ai|d2l-zh|natural-language-inference-bert.md|Markdown|398|0|72
115|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/gd.md|d2l-ai|d2l-zh|gd.md|Markdown|397|0|109
116|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preface/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|397|0|65
117|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/bert-dataset.md|d2l-ai|d2l-zh|bert-dataset.md|Markdown|395|0|53
118|./src/_00/output/Python/d2l-ai~d2l-zh/img/rec-caser.svg|d2l-ai|d2l-zh|rec-caser.svg|SVG|394|0|0
119|./src/_00/output/Python/d2l-ai~d2l-zh/img/anchor-label.svg|d2l-ai|d2l-zh|anchor-label.svg|SVG|392|0|0
120|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/semantic-segmentation-and-dataset_origin.md|d2l-ai|d2l-zh|semantic-segmentation-and-dataset_origin.md|Markdown|390|0|73
121|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/linear-regression-scratch_origin.md|d2l-ai|d2l-zh|linear-regression-scratch_origin.md|Markdown|388|0|70
122|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/language-models-and-dataset.md|d2l-ai|d2l-zh|language-models-and-dataset.md|Markdown|388|0|76
123|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/attention-scoring-functions_origin.md|d2l-ai|d2l-zh|attention-scoring-functions_origin.md|Markdown|387|0|62
124|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/fcn_origin.md|d2l-ai|d2l-zh|fcn_origin.md|Markdown|381|0|69
125|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/bert-dataset_origin.md|d2l-ai|d2l-zh|bert-dataset_origin.md|Markdown|381|0|47
126|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/nadaraya-waston_origin.md|d2l-ai|d2l-zh|nadaraya-waston_origin.md|Markdown|380|0|86
127|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/googlenet.md|d2l-ai|d2l-zh|googlenet.md|Markdown|380|0|67
128|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/googlenet_origin.md|d2l-ai|d2l-zh|googlenet_origin.md|Markdown|380|0|58
129|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/environment.md|d2l-ai|d2l-zh|environment.md|Markdown|376|0|101
130|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/autograd.md|d2l-ai|d2l-zh|autograd.md|Markdown|376|0|83
131|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/hybridize.md|d2l-ai|d2l-zh|hybridize.md|Markdown|372|0|103
132|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/resnet_origin.md|d2l-ai|d2l-zh|resnet_origin.md|Markdown|372|0|72
133|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/multihead-attention.md|d2l-ai|d2l-zh|multihead-attention.md|Markdown|371|0|69
134|./src/_00/output/Python/d2l-ai~d2l-zh/img/rec-seq-data.svg|d2l-ai|d2l-zh|rec-seq-data.svg|SVG|369|0|0
135|./src/_00/output/Python/d2l-ai~d2l-zh/img/rec-ranking.svg|d2l-ai|d2l-zh|rec-ranking.svg|SVG|368|0|0
136|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/language-models-and-dataset_origin.md|d2l-ai|d2l-zh|language-models-and-dataset_origin.md|Markdown|364|0|77
137|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/image-augmentation_origin.md|d2l-ai|d2l-zh|image-augmentation_origin.md|Markdown|363|0|76
138|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/natural-language-inference-attention_origin.md|d2l-ai|d2l-zh|natural-language-inference-attention_origin.md|Markdown|363|0|84
139|./src/_00/output/Python/d2l-ai~d2l-zh/img/resnet18.svg|d2l-ai|d2l-zh|resnet18.svg|SVG|363|0|0
140|./src/_00/output/Python/d2l-ai~d2l-zh/img/falseshare.svg|d2l-ai|d2l-zh|falseshare.svg|SVG|362|0|0
141|./src/_00/output/Python/d2l-ai~d2l-zh/img/inception.svg|d2l-ai|d2l-zh|inception.svg|SVG|360|0|0
142|./src/_00/output/Python/d2l-ai~d2l-zh/img/a77.svg|d2l-ai|d2l-zh|a77.svg|SVG|359|0|0
143|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/fine-tuning.md|d2l-ai|d2l-zh|fine-tuning.md|Markdown|356|0|80
144|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/sentiment-analysis-cnn_origin.md|d2l-ai|d2l-zh|sentiment-analysis-cnn_origin.md|Markdown|356|0|67
145|./src/_00/output/Python/d2l-ai~d2l-zh/img/deep-rnn.svg|d2l-ai|d2l-zh|deep-rnn.svg|SVG|355|0|0
146|./src/_00/output/Python/d2l-ai~d2l-zh/img/threading.svg|d2l-ai|d2l-zh|threading.svg|SVG|353|0|0
147|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/linear-regression-scratch.md|d2l-ai|d2l-zh|linear-regression-scratch.md|Markdown|352|0|68
148|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/bptt_origin.md|d2l-ai|d2l-zh|bptt_origin.md|Markdown|350|0|77
149|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/momentum.md|d2l-ai|d2l-zh|momentum.md|Markdown|348|0|98
150|./src/_00/output/Python/d2l-ai~d2l-zh/img/resnet-block.svg|d2l-ai|d2l-zh|resnet-block.svg|SVG|348|0|0
151|./src/_00/output/Python/d2l-ai~d2l-zh/img/cnn-rnn-self-attention.svg|d2l-ai|d2l-zh|cnn-rnn-self-attention.svg|SVG|347|0|0
152|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/autograd_origin.md|d2l-ai|d2l-zh|autograd_origin.md|Markdown|346|0|70
153|./src/_00/output/Python/d2l-ai~d2l-zh/img/trans_conv_stride2.svg|d2l-ai|d2l-zh|trans_conv_stride2.svg|SVG|346|0|0
154|./src/_00/output/Python/d2l-ai~d2l-zh/img/gru-2.svg|d2l-ai|d2l-zh|gru-2.svg|SVG|345|0|0
155|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/multiple-gpus_origin.md|d2l-ai|d2l-zh|multiple-gpus_origin.md|Markdown|343|0|71
156|./src/_00/output/Python/d2l-ai~d2l-zh/img/rec-neumf.svg|d2l-ai|d2l-zh|rec-neumf.svg|SVG|343|0|0
157|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/sequence_origin.md|d2l-ai|d2l-zh|sequence_origin.md|Markdown|342|0|82
158|./src/_00/output/Python/d2l-ai~d2l-zh/img/ps.svg|d2l-ai|d2l-zh|ps.svg|SVG|342|0|0
159|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/natural-language-inference-bert_origin.md|d2l-ai|d2l-zh|natural-language-inference-bert_origin.md|Markdown|340|0|55
160|./src/_00/output/Python/d2l-ai~d2l-zh/img/bert-two-seqs.svg|d2l-ai|d2l-zh|bert-two-seqs.svg|SVG|340|0|0
161|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/softmax-regression_origin.md|d2l-ai|d2l-zh|softmax-regression_origin.md|Markdown|338|0|78
162|./src/_00/output/Python/d2l-ai~d2l-zh/img/nlp-map-app.svg|d2l-ai|d2l-zh|nlp-map-app.svg|SVG|336|0|0
163|./src/_00/output/Python/d2l-ai~d2l-zh/img/nlp-map-nli-attention.svg|d2l-ai|d2l-zh|nlp-map-nli-attention.svg|SVG|336|0|0
164|./src/_00/output/Python/d2l-ai~d2l-zh/img/nlp-map-nli-bert.svg|d2l-ai|d2l-zh|nlp-map-nli-bert.svg|SVG|336|0|0
165|./src/_00/output/Python/d2l-ai~d2l-zh/img/nlp-map-pretrain.svg|d2l-ai|d2l-zh|nlp-map-pretrain.svg|SVG|336|0|0
166|./src/_00/output/Python/d2l-ai~d2l-zh/img/nlp-map-sa-cnn.svg|d2l-ai|d2l-zh|nlp-map-sa-cnn.svg|SVG|336|0|0
167|./src/_00/output/Python/d2l-ai~d2l-zh/img/nlp-map-sa-rnn.svg|d2l-ai|d2l-zh|nlp-map-sa-rnn.svg|SVG|336|0|0
168|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/image-classification-dataset.md|d2l-ai|d2l-zh|image-classification-dataset.md|Markdown|334|0|64
169|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/probability_origin.md|d2l-ai|d2l-zh|probability_origin.md|Markdown|334|0|108
170|./src/_00/output/Python/d2l-ai~d2l-zh/img/dropout2.svg|d2l-ai|d2l-zh|dropout2.svg|SVG|334|0|0
171|./src/_00/output/Python/d2l-ai~d2l-zh/img/conv-stride.svg|d2l-ai|d2l-zh|conv-stride.svg|SVG|333|0|0
172|./src/_00/output/Python/d2l-ai~d2l-zh/img/marginal.svg|d2l-ai|d2l-zh|marginal.svg|SVG|333|0|0
173|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/word-embedding-dataset.md|d2l-ai|d2l-zh|word-embedding-dataset.md|Markdown|328|0|77
174|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/bert-pretraining.md|d2l-ai|d2l-zh|bert-pretraining.md|Markdown|326|0|46
175|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/word2vec-pretraining.md|d2l-ai|d2l-zh|word2vec-pretraining.md|Markdown|324|0|70
176|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/densenet_origin.md|d2l-ai|d2l-zh|densenet_origin.md|Markdown|323|0|74
177|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/self-attention-and-positional-encoding.md|d2l-ai|d2l-zh|self-attention-and-positional-encoding.md|Markdown|322|0|60
178|./src/_00/output/Python/d2l-ai~d2l-zh/img/lstm-1.svg|d2l-ai|d2l-zh|lstm-1.svg|SVG|322|0|0
179|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/rnn-concise.md|d2l-ai|d2l-zh|rnn-concise.md|Markdown|321|0|60
180|./src/_00/output/Python/d2l-ai~d2l-zh/img/rec-intro.svg|d2l-ai|d2l-zh|rec-intro.svg|SVG|321|0|0
181|./src/_00/output/Python/d2l-ai~d2l-zh/img/rnn-train.svg|d2l-ai|d2l-zh|rnn-train.svg|SVG|321|0|0
182|./src/_00/output/Python/d2l-ai~d2l-zh/img/bert-one-seq.svg|d2l-ai|d2l-zh|bert-one-seq.svg|SVG|318|0|0
183|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/bahdanau-attention_origin.md|d2l-ai|d2l-zh|bahdanau-attention_origin.md|Markdown|315|0|47
184|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/multiple-gpus-concise.md|d2l-ai|d2l-zh|multiple-gpus-concise.md|Markdown|315|0|49
185|./src/_00/output/Python/d2l-ai~d2l-zh/img/attention-output.svg|d2l-ai|d2l-zh|attention-output.svg|SVG|311|0|0
186|./src/_00/output/Python/d2l-ai~d2l-zh/img/finetune.svg|d2l-ai|d2l-zh|finetune.svg|SVG|311|0|0
187|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/hybridize_origin.md|d2l-ai|d2l-zh|hybridize_origin.md|Markdown|310|0|96
188|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/machine-translation-and-dataset_origin.md|d2l-ai|d2l-zh|machine-translation-and-dataset_origin.md|Markdown|310|0|46
189|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/self-attention-and-positional-encoding_origin.md|d2l-ai|d2l-zh|self-attention-and-positional-encoding_origin.md|Markdown|309|0|53
190|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/conv-layer.md|d2l-ai|d2l-zh|conv-layer.md|Markdown|309|0|79
191|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/word2vec-pretraining_origin.md|d2l-ai|d2l-zh|word2vec-pretraining_origin.md|Markdown|308|0|60
192|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/numerical-stability-and-init_origin.md|d2l-ai|d2l-zh|numerical-stability-and-init_origin.md|Markdown|307|0|68
193|./src/_00/output/Python/d2l-ai~d2l-zh/img/self-attention.svg|d2l-ai|d2l-zh|self-attention.svg|SVG|300|0|0
194|./src/_00/output/Python/d2l-ai~d2l-zh/img/seq2seq.svg|d2l-ai|d2l-zh|seq2seq.svg|SVG|297|0|0
195|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/sentiment-analysis-cnn.md|d2l-ai|d2l-zh|sentiment-analysis-cnn.md|Markdown|294|0|70
196|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/fine-tuning_origin.md|d2l-ai|d2l-zh|fine-tuning_origin.md|Markdown|292|0|81
197|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/convexity.md|d2l-ai|d2l-zh|convexity.md|Markdown|290|0|111
198|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/gru_origin.md|d2l-ai|d2l-zh|gru_origin.md|Markdown|285|0|71
199|./src/_00/output/Python/d2l-ai~d2l-zh/img/contribute.svg|d2l-ai|d2l-zh|contribute.svg|SVG|283|0|0
200|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/transposed-conv_origin.md|d2l-ai|d2l-zh|transposed-conv_origin.md|Markdown|280|0|55
201|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/why-conv_origin.md|d2l-ai|d2l-zh|why-conv_origin.md|Markdown|280|0|59
202|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/bert-pretraining_origin.md|d2l-ai|d2l-zh|bert-pretraining_origin.md|Markdown|277|0|36
203|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/padding-and-strides_origin.md|d2l-ai|d2l-zh|padding-and-strides_origin.md|Markdown|276|0|48
204|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/natural-language-inference-and-dataset.md|d2l-ai|d2l-zh|natural-language-inference-and-dataset.md|Markdown|276|0|64
205|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/chapter_natural-language-processing/machine-translation.md|d2l-ai|d2l-zh|machine-translation.md|Markdown|274|0|75
206|./src/_00/output/Python/d2l-ai~d2l-zh/img/bw-hierarchy.svg|d2l-ai|d2l-zh|bw-hierarchy.svg|SVG|274|0|0
207|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/alexnet.md|d2l-ai|d2l-zh|alexnet.md|Markdown|272|0|62
208|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/rnn.md|d2l-ai|d2l-zh|rnn.md|Markdown|272|0|59
209|./src/_00/output/Python/d2l-ai~d2l-zh/img/beam-search.svg|d2l-ai|d2l-zh|beam-search.svg|SVG|272|0|0
210|./src/_00/output/Python/d2l-ai~d2l-zh/img/lang-model-data.svg|d2l-ai|d2l-zh|lang-model-data.svg|SVG|271|0|0
211|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/calculus_origin.md|d2l-ai|d2l-zh|calculus_origin.md|Markdown|270|0|84
212|./src/_00/output/Python/d2l-ai~d2l-zh/img/timemachine-5gram.svg|d2l-ai|d2l-zh|timemachine-5gram.svg|SVG|270|0|0
213|./src/_00/output/Python/d2l-ai~d2l-zh/img/trans_conv.svg|d2l-ai|d2l-zh|trans_conv.svg|SVG|269|0|0
214|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/adam.md|d2l-ai|d2l-zh|adam.md|Markdown|266|0|57
215|./src/_00/output/Python/d2l-ai~d2l-zh/img/seq2seq-predict.svg|d2l-ai|d2l-zh|seq2seq-predict.svg|SVG|266|0|0
216|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/read-write.md|d2l-ai|d2l-zh|read-write.md|Markdown|264|0|62
217|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/convexity_origin.md|d2l-ai|d2l-zh|convexity_origin.md|Markdown|263|0|114
218|./src/_00/output/Python/d2l-ai~d2l-zh/img/lstm-0.svg|d2l-ai|d2l-zh|lstm-0.svg|SVG|262|0|0
219|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/pooling_origin.md|d2l-ai|d2l-zh|pooling_origin.md|Markdown|261|0|57
220|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/bptt.md|d2l-ai|d2l-zh|bptt.md|Markdown|261|0|62
221|./src/_00/output/Python/d2l-ai~d2l-zh/img/rnn-bptt.svg|d2l-ai|d2l-zh|rnn-bptt.svg|SVG|261|0|0
222|./src/_00/output/Python/d2l-ai~d2l-zh/img/neuron.svg|d2l-ai|d2l-zh|neuron.svg|SVG|260|1|8
223|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/pooling.md|d2l-ai|d2l-zh|pooling.md|Markdown|257|0|66
224|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/multihead-attention_origin.md|d2l-ai|d2l-zh|multihead-attention_origin.md|Markdown|256|0|53
225|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/softmax-regression.md|d2l-ai|d2l-zh|softmax-regression.md|Markdown|255|0|69
226|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/machine-translation-and-dataset.md|d2l-ai|d2l-zh|machine-translation-and-dataset.md|Markdown|255|0|46
227|./src/_00/output/Python/d2l-ai~d2l-zh/img/conv1d-2d.svg|d2l-ai|d2l-zh|conv1d-2d.svg|SVG|254|0|0
228|./src/_00/output/Python/d2l-ai~d2l-zh/img/conv1d-channel.svg|d2l-ai|d2l-zh|conv1d-channel.svg|SVG|254|0|0
229|./src/_00/output/Python/d2l-ai~d2l-zh/img/rnn.svg|d2l-ai|d2l-zh|rnn.svg|SVG|254|0|0
230|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/custom-layer.md|d2l-ai|d2l-zh|custom-layer.md|Markdown|253|0|64
231|./src/_00/output/Python/d2l-ai~d2l-zh/img/mobo-symbol.svg|d2l-ai|d2l-zh|mobo-symbol.svg|SVG|252|0|0
232|./src/_00/output/Python/d2l-ai~d2l-zh/img/sum-order.svg|d2l-ai|d2l-zh|sum-order.svg|SVG|252|0|0
233|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/adagrad.md|d2l-ai|d2l-zh|adagrad.md|Markdown|251|0|64
234|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/sentiment-analysis-rnn.md|d2l-ai|d2l-zh|sentiment-analysis-rnn.md|Markdown|249|0|49
235|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/lstm_origin.md|d2l-ai|d2l-zh|lstm_origin.md|Markdown|248|0|76
236|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/calculus.md|d2l-ai|d2l-zh|calculus.md|Markdown|247|0|77
237|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/bi-rnn.md|d2l-ai|d2l-zh|bi-rnn.md|Markdown|247|0|54
238|./src/_00/output/Python/d2l-ai~d2l-zh/img/gan.svg|d2l-ai|d2l-zh|gan.svg|SVG|246|0|0
239|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/momentum_origin.md|d2l-ai|d2l-zh|momentum_origin.md|Markdown|244|0|92
240|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/gd_origin.md|d2l-ai|d2l-zh|gd_origin.md|Markdown|243|0|105
241|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/multiple-gpus-concise_origin.md|d2l-ai|d2l-zh|multiple-gpus-concise_origin.md|Markdown|242|0|44
242|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/image-classification-dataset_origin.md|d2l-ai|d2l-zh|image-classification-dataset_origin.md|Markdown|242|0|52
243|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/similarity-analogy_origin.md|d2l-ai|d2l-zh|similarity-analogy_origin.md|Markdown|241|0|53
244|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/backprop_origin.md|d2l-ai|d2l-zh|backprop_origin.md|Markdown|240|0|56
245|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/numerical-stability-and-init.md|d2l-ai|d2l-zh|numerical-stability-and-init.md|Markdown|239|0|60
246|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/object-detection-dataset.md|d2l-ai|d2l-zh|object-detection-dataset.md|Markdown|237|0|42
247|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/transposed-conv.md|d2l-ai|d2l-zh|transposed-conv.md|Markdown|234|0|57
248|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/channels_origin.md|d2l-ai|d2l-zh|channels_origin.md|Markdown|234|0|47
249|./src/_00/output/Python/d2l-ai~d2l-zh/img/neural-style.svg|d2l-ai|d2l-zh|neural-style.svg|SVG|234|0|0
250|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/natural-language-inference-and-dataset_origin.md|d2l-ai|d2l-zh|natural-language-inference-and-dataset_origin.md|Markdown|233|0|57
251|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/glove_origin.md|d2l-ai|d2l-zh|glove_origin.md|Markdown|233|0|52
252|./src/_00/output/Python/d2l-ai~d2l-zh/img/faster-rcnn.svg|d2l-ai|d2l-zh|faster-rcnn.svg|SVG|233|0|0
253|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/vgg_origin.md|d2l-ai|d2l-zh|vgg_origin.md|Markdown|231|0|45
254|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/rcnn_origin.md|d2l-ai|d2l-zh|rcnn_origin.md|Markdown|230|0|67
255|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/sentiment-analysis-rnn_origin.md|d2l-ai|d2l-zh|sentiment-analysis-rnn_origin.md|Markdown|229|0|43
256|./src/_00/output/Python/d2l-ai~d2l-zh/img/mlp.svg|d2l-ai|d2l-zh|mlp.svg|SVG|229|0|0
257|./src/_00/output/Python/d2l-ai~d2l-zh/img/gru-1.svg|d2l-ai|d2l-zh|gru-1.svg|SVG|228|0|0
258|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/read-write_origin.md|d2l-ai|d2l-zh|read-write_origin.md|Markdown|227|0|51
259|./src/_00/output/Python/d2l-ai~d2l-zh/img/birnn.svg|d2l-ai|d2l-zh|birnn.svg|SVG|227|0|0
260|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/vgg.md|d2l-ai|d2l-zh|vgg.md|Markdown|226|0|54
261|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/mlp-scratch.md|d2l-ai|d2l-zh|mlp-scratch.md|Markdown|225|0|54
262|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/rnn_origin.md|d2l-ai|d2l-zh|rnn_origin.md|Markdown|224|0|61
263|./src/_00/output/Python/d2l-ai~d2l-zh/img/sequence-model.svg|d2l-ai|d2l-zh|sequence-model.svg|SVG|222|0|0
264|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/custom-layer_origin.md|d2l-ai|d2l-zh|custom-layer_origin.md|Markdown|221|0|54
265|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/async-computation.md|d2l-ai|d2l-zh|async-computation.md|Markdown|220|0|62
266|./src/_00/output/Python/d2l-ai~d2l-zh/img/residual-block.svg|d2l-ai|d2l-zh|residual-block.svg|SVG|219|0|0
267|./src/_00/output/Python/d2l-ai~d2l-zh/img/neon128.svg|d2l-ai|d2l-zh|neon128.svg|SVG|213|0|0
268|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/auto-parallelism.md|d2l-ai|d2l-zh|auto-parallelism.md|Markdown|212|0|60
269|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/object-detection-dataset_origin.md|d2l-ai|d2l-zh|object-detection-dataset_origin.md|Markdown|211|0|36
270|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/rnn-concise_origin.md|d2l-ai|d2l-zh|rnn-concise_origin.md|Markdown|211|0|38
271|./src/_00/output/Python/d2l-ai~d2l-zh/img/functionclasses.svg|d2l-ai|d2l-zh|functionclasses.svg|SVG|209|0|0
272|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/nin.md|d2l-ai|d2l-zh|nin.md|Markdown|208|0|36
273|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/encoder-decoder.md|d2l-ai|d2l-zh|encoder-decoder.md|Markdown|208|0|49
274|./src/_00/output/Python/d2l-ai~d2l-zh/img/roi.svg|d2l-ai|d2l-zh|roi.svg|SVG|206|0|0
275|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/subword-embedding_origin.md|d2l-ai|d2l-zh|subword-embedding_origin.md|Markdown|205|0|39
276|./src/_00/output/Python/d2l-ai~d2l-zh/img/s2s-prob1.svg|d2l-ai|d2l-zh|s2s-prob1.svg|SVG|205|0|0
277|./src/_00/output/Python/d2l-ai~d2l-zh/img/s2s-prob2.svg|d2l-ai|d2l-zh|s2s-prob2.svg|SVG|205|0|0
278|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/mlp-scratch_origin.md|d2l-ai|d2l-zh|mlp-scratch_origin.md|Markdown|204|0|47
279|./src/_00/output/Python/d2l-ai~d2l-zh/img/data-parallel.svg|d2l-ai|d2l-zh|data-parallel.svg|SVG|203|0|0
280|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/attention-cues_origin.md|d2l-ai|d2l-zh|attention-cues_origin.md|Markdown|202|0|36
281|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/nin_origin.md|d2l-ai|d2l-zh|nin_origin.md|Markdown|202|0|32
282|./src/_00/output/Python/d2l-ai~d2l-zh/img/forward.svg|d2l-ai|d2l-zh|forward.svg|SVG|202|0|0
283|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/similarity-analogy.md|d2l-ai|d2l-zh|similarity-analogy.md|Markdown|200|0|54
284|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/rmsprop.md|d2l-ai|d2l-zh|rmsprop.md|Markdown|200|0|44
285|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/sgd_origin.md|d2l-ai|d2l-zh|sgd_origin.md|Markdown|200|0|89
286|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/padding-and-strides.md|d2l-ai|d2l-zh|padding-and-strides.md|Markdown|197|0|55
287|./src/_00/output/Python/d2l-ai~d2l-zh/img/seq2seq-attention-details.svg|d2l-ai|d2l-zh|seq2seq-attention-details.svg|SVG|195|0|0
288|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/sentiment-analysis-and-dataset_origin.md|d2l-ai|d2l-zh|sentiment-analysis-and-dataset_origin.md|Markdown|194|0|38
289|./src/_00/output/Python/d2l-ai~d2l-zh/img/ssd.svg|d2l-ai|d2l-zh|ssd.svg|SVG|194|0|0
290|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/approx-training_origin.md|d2l-ai|d2l-zh|approx-training_origin.md|Markdown|193|0|45
291|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.md|d2l-ai|d2l-zh|sentiment-analysis-and-dataset.md|Markdown|191|0|39
292|./src/_00/output/Python/d2l-ai~d2l-zh/img/frontends.svg|d2l-ai|d2l-zh|frontends.svg|SVG|190|0|0
293|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/async-computation_origin.md|d2l-ai|d2l-zh|async-computation_origin.md|Markdown|188|0|56
294|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/text-preprocessing.md|d2l-ai|d2l-zh|text-preprocessing.md|Markdown|188|0|41
295|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/optimization-intro_origin.md|d2l-ai|d2l-zh|optimization-intro_origin.md|Markdown|186|0|45
296|./src/_00/output/Python/d2l-ai~d2l-zh/config.ini|d2l-ai|d2l-zh|config.ini|INI|186|0|70
297|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/multiscale-object-detection_origin.md|d2l-ai|d2l-zh|multiscale-object-detection_origin.md|Markdown|185|0|38
298|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/adam_origin.md|d2l-ai|d2l-zh|adam_origin.md|Markdown|184|0|51
299|./src/_00/output/Python/d2l-ai~d2l-zh/img/mask-rcnn.svg|d2l-ai|d2l-zh|mask-rcnn.svg|SVG|184|0|0
300|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/optimization-intro.md|d2l-ai|d2l-zh|optimization-intro.md|Markdown|183|0|50
301|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/sgd.md|d2l-ai|d2l-zh|sgd.md|Markdown|183|0|79
302|./src/_00/output/Python/d2l-ai~d2l-zh/img/hi-softmax.svg|d2l-ai|d2l-zh|hi-softmax.svg|SVG|183|0|0
303|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/word2vec_origin.md|d2l-ai|d2l-zh|word2vec_origin.md|Markdown|182|0|80
304|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/bi-rnn_origin.md|d2l-ai|d2l-zh|bi-rnn_origin.md|Markdown|182|0|61
305|./src/_00/output/Python/d2l-ai~d2l-zh/img/multi-head-attention.svg|d2l-ai|d2l-zh|multi-head-attention.svg|SVG|181|0|0
306|./src/_00/output/Python/d2l-ai~d2l-zh/img/style-transfer.svg|d2l-ai|d2l-zh|style-transfer.svg|SVG|181|0|0
307|./src/_00/output/Python/d2l-ai~d2l-zh/img/correlation.svg|d2l-ai|d2l-zh|correlation.svg|SVG|180|0|0
308|./src/_00/output/Python/d2l-ai~d2l-zh/img/computegraph.svg|d2l-ai|d2l-zh|computegraph.svg|SVG|179|0|0
309|./src/_00/output/Python/d2l-ai~d2l-zh/img/qkv.svg|d2l-ai|d2l-zh|qkv.svg|SVG|179|0|0
310|./src/_00/output/Python/d2l-ai~d2l-zh/img/rect-trans.svg|d2l-ai|d2l-zh|rect-trans.svg|SVG|179|0|0
311|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/beam-search_origin.md|d2l-ai|d2l-zh|beam-search_origin.md|Markdown|178|0|39
312|./src/_00/output/Python/d2l-ai~d2l-zh/img/attention.svg|d2l-ai|d2l-zh|attention.svg|SVG|177|0|0
313|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/aws_origin.md|d2l-ai|d2l-zh|aws_origin.md|Markdown|176|0|90
314|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/softmax-regression-concise.md|d2l-ai|d2l-zh|softmax-regression-concise.md|Markdown|176|0|47
315|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/softmax-regression-concise_origin.md|d2l-ai|d2l-zh|softmax-regression-concise_origin.md|Markdown|175|0|41
316|./src/_00/output/Python/d2l-ai~d2l-zh/ci/docker/git-timesync|d2l-ai|d2l-zh|git-timesync|Bourne Shell|175|81|32
317|./src/_00/output/Python/d2l-ai~d2l-zh/img/pooling.svg|d2l-ai|d2l-zh|pooling.svg|SVG|175|0|0
318|./src/_00/output/Python/d2l-ai~d2l-zh/img/singlelayer.svg|d2l-ai|d2l-zh|singlelayer.svg|SVG|175|0|0
319|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/text-preprocessing_origin.md|d2l-ai|d2l-zh|text-preprocessing_origin.md|Markdown|174|0|35
320|./src/_00/output/Python/d2l-ai~d2l-zh/ci/submit-job.py|d2l-ai|d2l-zh|submit-job.py|Python|172|2|28
321|./src/_00/output/Python/d2l-ai~d2l-zh/img/seq2seq-details.svg|d2l-ai|d2l-zh|seq2seq-details.svg|SVG|171|0|0
322|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preface/index.md|d2l-ai|d2l-zh|index.md|Markdown|167|0|52
323|./src/_00/output/Python/d2l-ai~d2l-zh/img/fast-rcnn.svg|d2l-ai|d2l-zh|fast-rcnn.svg|SVG|167|0|0
324|./src/_00/output/Python/d2l-ai~d2l-zh/img/asyncgraph.svg|d2l-ai|d2l-zh|asyncgraph.svg|SVG|166|0|0
325|./src/_00/output/Python/d2l-ai~d2l-zh/STYLE_GUIDE.md|d2l-ai|d2l-zh|STYLE_GUIDE.md|Markdown|165|0|13
326|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/chapter_natural-language-processing/sentiment-analysis-rnn.md|d2l-ai|d2l-zh|sentiment-analysis-rnn.md|Markdown|163|0|63
327|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/adagrad_origin.md|d2l-ai|d2l-zh|adagrad_origin.md|Markdown|162|0|61
328|./src/_00/output/Python/d2l-ai~d2l-zh/img/conv-1x1.svg|d2l-ai|d2l-zh|conv-1x1.svg|SVG|160|0|0
329|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/hardware_origin.md|d2l-ai|d2l-zh|hardware_origin.md|Markdown|159|0|73
330|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/finetuning-bert_origin.md|d2l-ai|d2l-zh|finetuning-bert_origin.md|Markdown|159|0|35
331|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/attention-cues.md|d2l-ai|d2l-zh|attention-cues.md|Markdown|158|0|34
332|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/adadelta.md|d2l-ai|d2l-zh|adadelta.md|Markdown|158|0|42
333|./src/_00/output/Python/d2l-ai~d2l-zh/img/conv1d.svg|d2l-ai|d2l-zh|conv1d.svg|SVG|158|0|0
334|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/encoder-decoder_origin.md|d2l-ai|d2l-zh|encoder-decoder_origin.md|Markdown|157|0|34
335|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/hardware.md|d2l-ai|d2l-zh|hardware.md|Markdown|151|0|66
336|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/auto-parallelism_origin.md|d2l-ai|d2l-zh|auto-parallelism_origin.md|Markdown|150|0|50
337|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/channels.md|d2l-ai|d2l-zh|channels.md|Markdown|149|0|46
338|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_installation/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|149|0|73
339|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/bounding-box_origin.md|d2l-ai|d2l-zh|bounding-box_origin.md|Markdown|148|0|32
340|./src/_00/output/Python/d2l-ai~d2l-zh/img/fcn.svg|d2l-ai|d2l-zh|fcn.svg|SVG|148|0|0
341|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/rmsprop_origin.md|d2l-ai|d2l-zh|rmsprop_origin.md|Markdown|147|0|40
342|./src/_00/output/Python/d2l-ai~d2l-zh/img/densenet.svg|d2l-ai|d2l-zh|densenet.svg|SVG|142|0|0
343|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/multiscale-object-detection.md|d2l-ai|d2l-zh|multiscale-object-detection.md|Markdown|141|0|37
344|./src/_00/output/Python/d2l-ai~d2l-zh/TERMINOLOGY.md|d2l-ai|d2l-zh|TERMINOLOGY.md|Markdown|139|0|138
345|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_installation/index.md|d2l-ai|d2l-zh|index.md|Markdown|139|0|89
346|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/chapter_natural-language-processing/sentiment-analysis-cnn.md|d2l-ai|d2l-zh|sentiment-analysis-cnn.md|Markdown|139|0|58
347|./src/_00/output/Python/d2l-ai~d2l-zh/img/rec-mf.svg|d2l-ai|d2l-zh|rec-mf.svg|SVG|139|0|0
348|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/deep-rnn.md|d2l-ai|d2l-zh|deep-rnn.md|Markdown|138|0|36
349|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/beam-search.md|d2l-ai|d2l-zh|beam-search.md|Markdown|137|0|32
350|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/aws.md|d2l-ai|d2l-zh|aws.md|Markdown|136|0|69
351|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/backprop.md|d2l-ai|d2l-zh|backprop.md|Markdown|136|0|47
352|./src/_00/output/Python/d2l-ai~d2l-zh/.github/workflows/ci.yml|d2l-ai|d2l-zh|ci.yml|YAML|133|1|8
353|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/rcnn.md|d2l-ai|d2l-zh|rcnn.md|Markdown|133|0|49
354|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/chapter_recommender-systems/mf.md|d2l-ai|d2l-zh|mf.md|Markdown|133|0|36
355|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/deferred-init_origin.md|d2l-ai|d2l-zh|deferred-init_origin.md|Markdown|132|0|32
356|./src/_00/output/Python/d2l-ai~d2l-zh/img/eye-book.svg|d2l-ai|d2l-zh|eye-book.svg|SVG|132|0|0
357|./src/_00/output/Python/d2l-ai~d2l-zh/img/softmaxreg.svg|d2l-ai|d2l-zh|softmaxreg.svg|SVG|131|0|0
358|./src/_00/output/Python/d2l-ai~d2l-zh/img/space-division.svg|d2l-ai|d2l-zh|space-division.svg|SVG|131|0|0
359|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/subword-embedding.md|d2l-ai|d2l-zh|subword-embedding.md|Markdown|128|0|40
360|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/bounding-box.md|d2l-ai|d2l-zh|bounding-box.md|Markdown|127|0|31
361|./src/_00/output/Python/d2l-ai~d2l-zh/img/data-collection.svg|d2l-ai|d2l-zh|data-collection.svg|SVG|127|0|0
362|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/chapter_recommender-systems/movielens.md|d2l-ai|d2l-zh|movielens.md|Markdown|125|0|29
363|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/sagemaker_origin.md|d2l-ai|d2l-zh|sagemaker_origin.md|Markdown|124|0|47
364|./src/_00/output/Python/d2l-ai~d2l-zh/img/copyto.svg|d2l-ai|d2l-zh|copyto.svg|SVG|123|0|0
365|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/adadelta_origin.md|d2l-ai|d2l-zh|adadelta_origin.md|Markdown|122|0|39
366|./src/_00/output/Python/d2l-ai~d2l-zh/img/eye-coffee.svg|d2l-ai|d2l-zh|eye-coffee.svg|SVG|122|0|0
367|./src/_00/output/Python/d2l-ai~d2l-zh/img/proj-vec.svg|d2l-ai|d2l-zh|proj-vec.svg|SVG|121|0|0
368|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/deep-rnn_origin.md|d2l-ai|d2l-zh|deep-rnn_origin.md|Markdown|119|0|34
369|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/contributing.md|d2l-ai|d2l-zh|contributing.md|Markdown|118|0|43
370|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/mlp-concise.md|d2l-ai|d2l-zh|mlp-concise.md|Markdown|117|0|29
371|./src/_00/output/Python/d2l-ai~d2l-zh/img/hmm.svg|d2l-ai|d2l-zh|hmm.svg|SVG|117|0|0
372|./src/_00/output/Python/d2l-ai~d2l-zh/img/truncated-bptt.svg|d2l-ai|d2l-zh|truncated-bptt.svg|SVG|116|0|0
373|./src/_00/output/Python/d2l-ai~d2l-zh/img/grid-transform-filled.svg|d2l-ai|d2l-zh|grid-transform-filled.svg|SVG|115|0|0
374|./src/_00/output/Python/d2l-ai~d2l-zh/img/grid-transform.svg|d2l-ai|d2l-zh|grid-transform.svg|SVG|113|0|0
375|./src/_00/output/Python/d2l-ai~d2l-zh/img/capacity-vs-error.svg|d2l-ai|d2l-zh|capacity-vs-error.svg|SVG|111|0|0
376|./src/_00/output/Python/d2l-ai~d2l-zh/img/ml-loop.svg|d2l-ai|d2l-zh|ml-loop.svg|SVG|111|0|0
377|./src/_00/output/Python/d2l-ai~d2l-zh/img/supervised-learning.svg|d2l-ai|d2l-zh|supervised-learning.svg|SVG|111|0|0
378|./src/_00/output/Python/d2l-ai~d2l-zh/img/negSecDer.svg|d2l-ai|d2l-zh|negSecDer.svg|SVG|110|0|0
379|./src/_00/output/Python/d2l-ai~d2l-zh/img/posSecDer.svg|d2l-ai|d2l-zh|posSecDer.svg|SVG|110|0|0
380|./src/_00/output/Python/d2l-ai~d2l-zh/img/zeroSecDer.svg|d2l-ai|d2l-zh|zeroSecDer.svg|SVG|109|0|0
381|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/pandas.md|d2l-ai|d2l-zh|pandas.md|Markdown|107|0|33
382|./src/_00/output/Python/d2l-ai~d2l-zh/img/cbow.svg|d2l-ai|d2l-zh|cbow.svg|SVG|107|0|0
383|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/why-conv.md|d2l-ai|d2l-zh|why-conv.md|Markdown|106|0|45
384|./src/_00/output/Python/d2l-ai~d2l-zh/img/chain-net1.svg|d2l-ai|d2l-zh|chain-net1.svg|SVG|103|0|0
385|./src/_00/output/Python/d2l-ai~d2l-zh/img/space-division-3d.svg|d2l-ai|d2l-zh|space-division-3d.svg|SVG|103|0|0
386|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/deferred-init.md|d2l-ai|d2l-zh|deferred-init.md|Markdown|102|0|31
387|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/pandas_origin.md|d2l-ai|d2l-zh|pandas_origin.md|Markdown|102|0|32
388|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/jupyter_origin.md|d2l-ai|d2l-zh|jupyter_origin.md|Markdown|101|0|55
389|./src/_00/output/Python/d2l-ai~d2l-zh/img/singleneuron.svg|d2l-ai|d2l-zh|singleneuron.svg|SVG|101|0|0
390|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/mlp-concise_origin.md|d2l-ai|d2l-zh|mlp-concise_origin.md|Markdown|99|0|23
391|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/lookup-api.md|d2l-ai|d2l-zh|lookup-api.md|Markdown|99|0|30
392|./src/_00/output/Python/d2l-ai~d2l-zh/img/frontends/Canvas 1.svg|d2l-ai|d2l-zh|Canvas 1.svg|SVG|99|0|0
393|./src/_00/output/Python/d2l-ai~d2l-zh/img/skip-gram.svg|d2l-ai|d2l-zh|skip-gram.svg|SVG|95|0|0
394|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/chapter_natural-language-processing/similarity-analogy.md|d2l-ai|d2l-zh|similarity-analogy.md|Markdown|94|0|50
395|./src/_00/output/Python/d2l-ai~d2l-zh/img/vec-add.svg|d2l-ai|d2l-zh|vec-add.svg|SVG|92|0|0
396|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/chapter_recommender-systems/autorec.md|d2l-ai|d2l-zh|autorec.md|Markdown|91|0|27
397|./src/_00/output/Python/d2l-ai~d2l-zh/img/rl-environment.svg|d2l-ai|d2l-zh|rl-environment.svg|SVG|90|0|0
398|./src/_00/output/Python/d2l-ai~d2l-zh/img/encoder-decoder.svg|d2l-ai|d2l-zh|encoder-decoder.svg|SVG|87|0|0
399|./src/_00/output/Python/d2l-ai~d2l-zh/img/vec-angle.svg|d2l-ai|d2l-zh|vec-angle.svg|SVG|85|0|0
400|./src/_00/output/Python/d2l-ai~d2l-zh/img/capacity_vs_error.svg|d2l-ai|d2l-zh|capacity_vs_error.svg|SVG|84|0|0
401|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/sagemaker.md|d2l-ai|d2l-zh|sagemaker.md|Markdown|83|0|41
402|./src/_00/output/Python/d2l-ai~d2l-zh/.github/actions/submit-job/action.yml|d2l-ai|d2l-zh|action.yml|YAML|82|2|7
403|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/chapter_recommender-systems/fm.md|d2l-ai|d2l-zh|fm.md|Markdown|82|0|26
404|./src/_00/output/Python/d2l-ai~d2l-zh/img/wake-word.svg|d2l-ai|d2l-zh|wake-word.svg|SVG|82|0|0
405|./src/_00/output/Python/d2l-ai~d2l-zh/img/grid-points.svg|d2l-ai|d2l-zh|grid-points.svg|SVG|81|0|0
406|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/d2lzh/text/embedding.py|d2l-ai|d2l-zh|embedding.py|Python|80|5|10
407|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/contributing_origin.md|d2l-ai|d2l-zh|contributing_origin.md|Markdown|79|0|50
408|./src/_00/output/Python/d2l-ai~d2l-zh/img/chain-net2.svg|d2l-ai|d2l-zh|chain-net2.svg|SVG|77|0|0
409|./src/_00/output/Python/d2l-ai~d2l-zh/.github/workflows/build-docker.yml|d2l-ai|d2l-zh|build-docker.yml|YAML|76|4|8
410|./src/_00/output/Python/d2l-ai~d2l-zh/static/post_latex/main.py|d2l-ai|d2l-zh|main.py|Python|76|14|20
411|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/chapter_recommender-systems/ctr.md|d2l-ai|d2l-zh|ctr.md|Markdown|75|0|24
412|./src/_00/output/Python/d2l-ai~d2l-zh/img/iou.svg|d2l-ai|d2l-zh|iou.svg|SVG|75|0|0
413|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/lookup-api_origin.md|d2l-ai|d2l-zh|lookup-api_origin.md|Markdown|74|0|29
414|./src/_00/output/Python/d2l-ai~d2l-zh/img/densenet-block.svg|d2l-ai|d2l-zh|densenet-block.svg|SVG|73|0|0
415|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/jupyter.md|d2l-ai|d2l-zh|jupyter.md|Markdown|72|0|40
416|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/parameterserver_origin.md|d2l-ai|d2l-zh|parameterserver_origin.md|Markdown|72|0|47
417|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|71|0|7
418|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/word2vec.md|d2l-ai|d2l-zh|word2vec.md|Markdown|71|0|53
419|./src/_00/output/Python/d2l-ai~d2l-zh/img/par-vec.svg|d2l-ai|d2l-zh|par-vec.svg|SVG|69|0|0
420|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/parameterserver.md|d2l-ai|d2l-zh|parameterserver.md|Markdown|63|0|40
421|./src/_00/output/Python/d2l-ai~d2l-zh/img/add_norm.svg|d2l-ai|d2l-zh|add_norm.svg|SVG|62|0|0
422|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/d2l.md|d2l-ai|d2l-zh|d2l.md|Markdown|61|0|25
423|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|61|0|7
424|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/glove.md|d2l-ai|d2l-zh|glove.md|Markdown|60|0|37
425|./src/_00/output/Python/d2l-ai~d2l-zh/img/cat-dog-test.svg|d2l-ai|d2l-zh|cat-dog-test.svg|SVG|60|0|0
426|./src/_00/output/Python/d2l-ai~d2l-zh/img/cat-dog-train.svg|d2l-ai|d2l-zh|cat-dog-train.svg|SVG|60|0|0
427|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_notation/index.md|d2l-ai|d2l-zh|index.md|Markdown|59|0|14
428|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_notation/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|59|0|25
429|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|57|0|13
430|./src/_00/output/Python/d2l-ai~d2l-zh/README.md|d2l-ai|d2l-zh|README.md|Markdown|56|0|26
431|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/d2l_origin.md|d2l-ai|d2l-zh|d2l_origin.md|Markdown|55|0|43
432|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|55|0|9
433|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|55|0|6
434|./src/_00/output/Python/d2l-ai~d2l-zh/INFO.md|d2l-ai|d2l-zh|INFO.md|Markdown|54|0|28
435|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/approx-training.md|d2l-ai|d2l-zh|approx-training.md|Markdown|53|0|34
436|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|51|0|9
437|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|46|0|6
438|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/index.md|d2l-ai|d2l-zh|index.md|Markdown|46|0|8
439|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/index.md|d2l-ai|d2l-zh|index.md|Markdown|46|0|9
440|./src/_00/output/Python/d2l-ai~d2l-zh/img/segmentation.svg|d2l-ai|d2l-zh|segmentation.svg|SVG|45|0|0
441|./src/_00/output/Python/d2l-ai~d2l-zh/.github/actions/setup_env_vars/action.yml|d2l-ai|d2l-zh|action.yml|YAML|44|0|13
442|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|44|0|6
443|./src/_00/output/Python/d2l-ai~d2l-zh/img/sub-area.svg|d2l-ai|d2l-zh|sub-area.svg|SVG|43|0|0
444|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/selecting-servers-gpus_origin.md|d2l-ai|d2l-zh|selecting-servers-gpus_origin.md|Markdown|42|0|28
445|./src/_00/output/Python/d2l-ai~d2l-zh/ci/docker/d2l_job.sh|d2l-ai|d2l-zh|d2l_job.sh|Bourne Shell|42|14|12
446|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/finetuning-bert.md|d2l-ai|d2l-zh|finetuning-bert.md|Markdown|41|0|26
447|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.md|d2l-ai|d2l-zh|selecting-servers-gpus.md|Markdown|40|0|21
448|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|38|0|6
449|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/index.md|d2l-ai|d2l-zh|index.md|Markdown|36|0|7
450|./src/_00/output/Python/d2l-ai~d2l-zh/index.md|d2l-ai|d2l-zh|index.md|Markdown|36|0|13
451|./src/_00/output/Python/d2l-ai~d2l-zh/.github/workflows/clear-cache.yml|d2l-ai|d2l-zh|clear-cache.yml|YAML|35|0|4
452|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/index.md|d2l-ai|d2l-zh|index.md|Markdown|35|0|5
453|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|34|0|4
454|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/index.md|d2l-ai|d2l-zh|index.md|Markdown|32|0|7
455|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/index.md|d2l-ai|d2l-zh|index.md|Markdown|32|0|4
456|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_preliminaries/index.md|d2l-ai|d2l-zh|index.md|Markdown|32|0|8
457|./src/_00/output/Python/d2l-ai~d2l-zh/ci/docker/print_versions.py|d2l-ai|d2l-zh|print_versions.py|Python|32|8|11
458|./src/_00/output/Python/d2l-ai~d2l-zh/img/fit-linreg.svg|d2l-ai|d2l-zh|fit-linreg.svg|SVG|31|0|0
459|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computer-vision/index.md|d2l-ai|d2l-zh|index.md|Markdown|28|0|4
460|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/index.md|d2l-ai|d2l-zh|index.md|Markdown|28|0|6
461|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|28|0|6
462|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|27|0|8
463|./src/_00/output/Python/d2l-ai~d2l-zh/img/convex-intersect.svg|d2l-ai|d2l-zh|convex-intersect.svg|SVG|27|0|0
464|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/index.md|d2l-ai|d2l-zh|index.md|Markdown|26|0|3
465|./src/_00/output/Python/d2l-ai~d2l-zh/static/cache.sh|d2l-ai|d2l-zh|cache.sh|Bourne Shell|26|0|3
466|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/index.md|d2l-ai|d2l-zh|index.md|Markdown|25|0|6
467|./src/_00/output/Python/d2l-ai~d2l-zh/.github/workflow_scripts/build_pytorch.sh|d2l-ai|d2l-zh|build_pytorch.sh|Bourne Shell|24|7|10
468|./src/_00/output/Python/d2l-ai~d2l-zh/.github/workflow_scripts/build_and_deploy.sh|d2l-ai|d2l-zh|build_and_deploy.sh|Bourne Shell|23|8|14
469|./src/_00/output/Python/d2l-ai~d2l-zh/.github/workflow_scripts/build_tf.sh|d2l-ai|d2l-zh|build_tf.sh|Bourne Shell|22|7|10
470|./src/_00/output/Python/d2l-ai~d2l-zh/setup.py|d2l-ai|d2l-zh|setup.py|Python|22|0|2
471|./src/_00/output/Python/d2l-ai~d2l-zh/.github/workflow_scripts/build_mxnet.sh|d2l-ai|d2l-zh|build_mxnet.sh|Bourne Shell|21|13|10
472|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|21|0|4
473|./src/_00/output/Python/d2l-ai~d2l-zh/.github/workflow_scripts/build_paddle.sh|d2l-ai|d2l-zh|build_paddle.sh|Bourne Shell|20|7|10
474|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|20|0|3
475|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|19|0|5
476|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_optimization/index.md|d2l-ai|d2l-zh|index.md|Markdown|19|0|5
477|./src/_00/output/Python/d2l-ai~d2l-zh/ci/docker/Dockerfile.d2l-builder|d2l-ai|d2l-zh|Dockerfile.d2l-builder|Dockerfile|19|8|12
478|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/chapter_recommender-systems/index.md|d2l-ai|d2l-zh|index.md|Markdown|19|0|7
479|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/d2lzh/text/vocab.py|d2l-ai|d2l-zh|vocab.py|Python|19|1|2
480|./src/_00/output/Python/d2l-ai~d2l-zh/img/projections.svg|d2l-ai|d2l-zh|projections.svg|SVG|19|0|0
481|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_computational-performance/index.md|d2l-ai|d2l-zh|index.md|Markdown|18|0|3
482|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_linear-networks/index.md|d2l-ai|d2l-zh|index.md|Markdown|18|0|3
483|./src/_00/output/Python/d2l-ai~d2l-zh/.github/workflow_scripts/build_html.sh|d2l-ai|d2l-zh|build_html.sh|Bourne Shell|17|3|4
484|./src/_00/output/Python/d2l-ai~d2l-zh/img/pacman.svg|d2l-ai|d2l-zh|pacman.svg|SVG|17|0|0
485|./src/_00/output/Python/d2l-ai~d2l-zh/static/build.yml|d2l-ai|d2l-zh|build.yml|YAML|16|0|0
486|./src/_00/output/Python/d2l-ai~d2l-zh/img/mutual-information.svg|d2l-ai|d2l-zh|mutual-information.svg|SVG|15|0|0
487|./src/_00/output/Python/d2l-ai~d2l-zh/img/r-cnn.svg|d2l-ai|d2l-zh|r-cnn.svg|SVG|15|0|0
488|./src/_00/output/Python/d2l-ai~d2l-zh/ci/docker/Dockerfile.d2l-zh-mxnet|d2l-ai|d2l-zh|Dockerfile.d2l-zh-mxnet|Dockerfile|14|7|10
489|./src/_00/output/Python/d2l-ai~d2l-zh/ci/docker/Dockerfile.d2l-zh-paddle|d2l-ai|d2l-zh|Dockerfile.d2l-zh-paddle|Dockerfile|14|7|10
490|./src/_00/output/Python/d2l-ai~d2l-zh/img/nonconvex.svg|d2l-ai|d2l-zh|nonconvex.svg|SVG|14|0|0
491|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/index.md|d2l-ai|d2l-zh|index.md|Markdown|13|0|3
492|./src/_00/output/Python/d2l-ai~d2l-zh/ci/docker/Dockerfile.d2l-zh-tf|d2l-ai|d2l-zh|Dockerfile.d2l-zh-tf|Dockerfile|13|6|9
493|./src/_00/output/Python/d2l-ai~d2l-zh/ci/docker/Dockerfile.d2l-zh-torch|d2l-ai|d2l-zh|Dockerfile.d2l-zh-torch|Dockerfile|13|6|9
494|./src/_00/output/Python/d2l-ai~d2l-zh/img/polygon-circle.svg|d2l-ai|d2l-zh|polygon-circle.svg|SVG|13|0|0
495|./src/_00/output/Python/d2l-ai~d2l-zh/.github/workflow_scripts/setup_git.sh|d2l-ai|d2l-zh|setup_git.sh|Bourne Shell|11|3|4
496|./src/_00/output/Python/d2l-ai~d2l-zh/.github/workflow_scripts/utils.sh|d2l-ai|d2l-zh|utils.sh|Bourne Shell|11|7|8
497|./src/_00/output/Python/d2l-ai~d2l-zh/chapter_references/zreferences.md|d2l-ai|d2l-zh|zreferences.md|Markdown|6|0|5
498|./src/_00/output/Python/d2l-ai~d2l-zh/ci/docker/entry.sh|d2l-ai|d2l-zh|entry.sh|Bourne Shell|3|0|0
499|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/d2lzh/__init__.py|d2l-ai|d2l-zh|__init__.py|Python|3|0|1
500|./src/_00/output/Python/d2l-ai~d2l-zh/ci/docker/login_ecr.sh|d2l-ai|d2l-zh|login_ecr.sh|Bourne Shell|2|0|1
501|./src/_00/output/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/d2lzh/text/__init__.py|d2l-ai|d2l-zh|__init__.py|Python|2|0|0
502|./src/_00/output/Python/d2l-ai~d2l-zh/d2l/__init__.py|d2l-ai|d2l-zh|__init__.py|Python|1|7|4
503|./src/_00/output/Python/d2l-ai~d2l-zh/graffle/convert.sh|d2l-ai|d2l-zh|convert.sh|Bourne Shell|1|0|0
504|./src/_00/output/Python/d2l-ai~d2l-zh/img/flopsvsprice.svg|d2l-ai|d2l-zh|flopsvsprice.svg|SVG|1|0|0
505|./src/_00/output/Python/d2l-ai~d2l-zh/img/wattvsprice.svg|d2l-ai|d2l-zh|wattvsprice.svg|SVG|1|0|0
