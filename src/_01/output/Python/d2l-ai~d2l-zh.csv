path|owner|project|file|language|code|comment|blank
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/twogpu.svg|d2l-ai|d2l-zh|twogpu.svg|SVG|2983|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/d2l/paddle.py|d2l-ai|d2l-zh|paddle.py|Python|1851|457|372
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/d2l/torch.py|d2l-ai|d2l-zh|torch.py|Python|1844|450|372
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/d2l.bib|d2l-ai|d2l-zh|d2l.bib|TeX|1755|0|197
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/d2l/mxnet.py|d2l-ai|d2l-zh|mxnet.py|Python|1742|441|368
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/splitting.svg|d2l-ai|d2l-zh|splitting.svg|SVG|1469|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_introduction/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|1458|0|173
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/nvlink-twoloop.svg|d2l-ai|d2l-zh|nvlink-twoloop.svg|SVG|1134|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/transformer.md|d2l-ai|d2l-zh|transformer.md|Markdown|1010|0|151
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/skylake.svg|d2l-ai|d2l-zh|skylake.svg|SVG|1004|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/seq2seq.md|d2l-ai|d2l-zh|seq2seq.md|Markdown|999|0|124
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/d2l/tensorflow.py|d2l-ai|d2l-zh|tensorflow.py|Python|994|256|227
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/vgg.svg|d2l-ai|d2l-zh|vgg.svg|SVG|948|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/alexnet.svg|d2l-ai|d2l-zh|alexnet.svg|SVG|946|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/textcnn.svg|d2l-ai|d2l-zh|textcnn.svg|SVG|938|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/anchor.md|d2l-ai|d2l-zh|anchor.md|Markdown|893|0|126
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/rnn-scratch.md|d2l-ai|d2l-zh|rnn-scratch.md|Markdown|889|0|119
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/nin.svg|d2l-ai|d2l-zh|nin.svg|SVG|876|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/linear-algebra.md|d2l-ai|d2l-zh|linear-algebra.md|Markdown|873|0|238
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/static/frontpage/frontpage.html|d2l-ai|d2l-zh|frontpage.html|HTML|871|455|43
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/linear-algebra_origin.md|d2l-ai|d2l-zh|linear-algebra_origin.md|Markdown|869|0|225
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/ssd_origin.md|d2l-ai|d2l-zh|ssd_origin.md|Markdown|819|0|138
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/ssd.md|d2l-ai|d2l-zh|ssd.md|Markdown|818|0|160
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/anchor_origin.md|d2l-ai|d2l-zh|anchor_origin.md|Markdown|802|0|107
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/transformer_origin.md|d2l-ai|d2l-zh|transformer_origin.md|Markdown|778|0|107
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/ringsync.svg|d2l-ai|d2l-zh|ringsync.svg|SVG|763|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/seq2seq_origin.md|d2l-ai|d2l-zh|seq2seq_origin.md|Markdown|737|0|92
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/rnn-scratch_origin.md|d2l-ai|d2l-zh|rnn-scratch_origin.md|Markdown|726|0|105
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/ps-multimachine.svg|d2l-ai|d2l-zh|ps-multimachine.svg|SVG|719|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/minibatch-sgd.md|d2l-ai|d2l-zh|minibatch-sgd.md|Markdown|685|0|107
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/nvlink.svg|d2l-ai|d2l-zh|nvlink.svg|SVG|681|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/model-construction_origin.md|d2l-ai|d2l-zh|model-construction_origin.md|Markdown|646|0|89
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/bert-input.svg|d2l-ai|d2l-zh|bert-input.svg|SVG|644|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/d2lzh/utils.py|d2l-ai|d2l-zh|utils.py|Python|641|54|142
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/alexnet-original.svg|d2l-ai|d2l-zh|alexnet-original.svg|SVG|633|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/batch-norm_origin.md|d2l-ai|d2l-zh|batch-norm_origin.md|Markdown|628|0|84
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/model-construction.md|d2l-ai|d2l-zh|model-construction.md|Markdown|613|0|110
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/parameters.md|d2l-ai|d2l-zh|parameters.md|Markdown|609|0|130
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/kaggle-house-price_origin.md|d2l-ai|d2l-zh|kaggle-house-price_origin.md|Markdown|607|0|92
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/nadaraya-waston.md|d2l-ai|d2l-zh|nadaraya-waston.md|Markdown|588|0|115
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/kaggle-cifar10.md|d2l-ai|d2l-zh|kaggle-cifar10.md|Markdown|582|0|104
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/ndarray_origin.md|d2l-ai|d2l-zh|ndarray_origin.md|Markdown|580|0|130
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_introduction/index.md|d2l-ai|d2l-zh|index.md|Markdown|579|0|169
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/parameters_origin.md|d2l-ai|d2l-zh|parameters_origin.md|Markdown|569|0|114
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/environment_origin.md|d2l-ai|d2l-zh|environment_origin.md|Markdown|560|0|136
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/underfit-overfit_origin.md|d2l-ai|d2l-zh|underfit-overfit_origin.md|Markdown|560|0|92
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/lr-scheduler.md|d2l-ai|d2l-zh|lr-scheduler.md|Markdown|551|0|112
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/ndarray.md|d2l-ai|d2l-zh|ndarray.md|Markdown|548|0|135
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/linear-regression_origin.md|d2l-ai|d2l-zh|linear-regression_origin.md|Markdown|545|0|122
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/kaggle-house-price.md|d2l-ai|d2l-zh|kaggle-house-price.md|Markdown|539|0|93
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/softmax-regression-scratch.md|d2l-ai|d2l-zh|softmax-regression-scratch.md|Markdown|537|0|98
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/kaggle-dog.md|d2l-ai|d2l-zh|kaggle-dog.md|Markdown|536|0|88
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/batch-norm.md|d2l-ai|d2l-zh|batch-norm.md|Markdown|531|0|85
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/bert_origin.md|d2l-ai|d2l-zh|bert_origin.md|Markdown|530|0|84
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/blocks.svg|d2l-ai|d2l-zh|blocks.svg|SVG|514|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/softmax-regression-scratch_origin.md|d2l-ai|d2l-zh|softmax-regression-scratch_origin.md|Markdown|511|0|86
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/attention-scoring-functions.md|d2l-ai|d2l-zh|attention-scoring-functions.md|Markdown|508|0|81
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/kaggle-cifar10_origin.md|d2l-ai|d2l-zh|kaggle-cifar10_origin.md|Markdown|501|0|87
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/minibatch-sgd_origin.md|d2l-ai|d2l-zh|minibatch-sgd_origin.md|Markdown|499|0|93
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/multiple-gpus.md|d2l-ai|d2l-zh|multiple-gpus.md|Markdown|496|0|80
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/inception-full.svg|d2l-ai|d2l-zh|inception-full.svg|SVG|490|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/weight-decay_origin.md|d2l-ai|d2l-zh|weight-decay_origin.md|Markdown|489|0|73
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/bert.md|d2l-ai|d2l-zh|bert.md|Markdown|489|0|93
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/dropout_origin.md|d2l-ai|d2l-zh|dropout_origin.md|Markdown|484|0|82
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/mlp_origin.md|d2l-ai|d2l-zh|mlp_origin.md|Markdown|484|0|95
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/rec-deepfm.svg|d2l-ai|d2l-zh|rec-deepfm.svg|SVG|477|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/underfit-overfit.md|d2l-ai|d2l-zh|underfit-overfit.md|Markdown|474|0|90
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/semantic-segmentation-and-dataset.md|d2l-ai|d2l-zh|semantic-segmentation-and-dataset.md|Markdown|473|0|85
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/sequence.md|d2l-ai|d2l-zh|sequence.md|Markdown|471|0|87
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/image-augmentation.md|d2l-ai|d2l-zh|image-augmentation.md|Markdown|468|0|88
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/nli_attention.svg|d2l-ai|d2l-zh|nli_attention.svg|SVG|466|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/neural-style_origin.md|d2l-ai|d2l-zh|neural-style_origin.md|Markdown|463|0|96
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/lenet.svg|d2l-ai|d2l-zh|lenet.svg|SVG|462|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/ps-distributed.svg|d2l-ai|d2l-zh|ps-distributed.svg|SVG|462|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/weight-decay.md|d2l-ai|d2l-zh|weight-decay.md|Markdown|461|0|71
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/neural-style.md|d2l-ai|d2l-zh|neural-style.md|Markdown|459|0|104
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/dropout.md|d2l-ai|d2l-zh|dropout.md|Markdown|457|0|92
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/natural-language-inference-attention.md|d2l-ai|d2l-zh|natural-language-inference-attention.md|Markdown|456|0|98
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/nin-compare.svg|d2l-ai|d2l-zh|nin-compare.svg|SVG|455|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/seq2seq-attention.svg|d2l-ai|d2l-zh|seq2seq-attention.svg|SVG|446|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/kaggle-dog_origin.md|d2l-ai|d2l-zh|kaggle-dog_origin.md|Markdown|442|0|76
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/lstm-3.svg|d2l-ai|d2l-zh|lstm-3.svg|SVG|440|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/linear-regression-concise.md|d2l-ai|d2l-zh|linear-regression-concise.md|Markdown|434|0|89
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/statistical-significance.svg|d2l-ai|d2l-zh|statistical-significance.svg|SVG|434|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/alexnet_origin.md|d2l-ai|d2l-zh|alexnet_origin.md|Markdown|431|0|59
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/use-gpu_origin.md|d2l-ai|d2l-zh|use-gpu_origin.md|Markdown|431|0|91
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/linear-regression-concise_origin.md|d2l-ai|d2l-zh|linear-regression-concise_origin.md|Markdown|431|0|78
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/falsesharing.svg|d2l-ai|d2l-zh|falsesharing.svg|SVG|430|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/resnet.md|d2l-ai|d2l-zh|resnet.md|Markdown|429|0|76
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/ps-multips.svg|d2l-ai|d2l-zh|ps-multips.svg|SVG|429|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/book-org.svg|d2l-ai|d2l-zh|book-org.svg|SVG|428|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/gru-3.svg|d2l-ai|d2l-zh|gru-3.svg|SVG|427|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/elmo-gpt-bert.svg|d2l-ai|d2l-zh|elmo-gpt-bert.svg|SVG|426|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/transformer.svg|d2l-ai|d2l-zh|transformer.svg|SVG|426|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/bert-tagging.svg|d2l-ai|d2l-zh|bert-tagging.svg|SVG|425|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/gru.md|d2l-ai|d2l-zh|gru.md|Markdown|422|0|87
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/use-gpu.md|d2l-ai|d2l-zh|use-gpu.md|Markdown|420|0|100
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/lstm.md|d2l-ai|d2l-zh|lstm.md|Markdown|419|0|85
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/word-embedding-dataset_origin.md|d2l-ai|d2l-zh|word-embedding-dataset_origin.md|Markdown|416|0|79
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/lstm-2.svg|d2l-ai|d2l-zh|lstm-2.svg|SVG|412|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/probability.md|d2l-ai|d2l-zh|probability.md|Markdown|411|0|103
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/linear-regression.md|d2l-ai|d2l-zh|linear-regression.md|Markdown|410|0|114
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/lenet-vert.svg|d2l-ai|d2l-zh|lenet-vert.svg|SVG|409|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/fcn.md|d2l-ai|d2l-zh|fcn.md|Markdown|408|0|80
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/lenet_origin.md|d2l-ai|d2l-zh|lenet_origin.md|Markdown|406|0|49
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/conv-layer_origin.md|d2l-ai|d2l-zh|conv-layer_origin.md|Markdown|405|0|77
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/lr-scheduler_origin.md|d2l-ai|d2l-zh|lr-scheduler_origin.md|Markdown|405|0|95
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/bert-qa.svg|d2l-ai|d2l-zh|bert-qa.svg|SVG|404|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/conv-pad.svg|d2l-ai|d2l-zh|conv-pad.svg|SVG|403|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/bahdanau-attention.md|d2l-ai|d2l-zh|bahdanau-attention.md|Markdown|401|0|60
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/densenet.md|d2l-ai|d2l-zh|densenet.md|Markdown|401|0|80
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/lenet.md|d2l-ai|d2l-zh|lenet.md|Markdown|401|0|54
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/conv-multi-in.svg|d2l-ai|d2l-zh|conv-multi-in.svg|SVG|401|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/mlp.md|d2l-ai|d2l-zh|mlp.md|Markdown|398|0|89
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/natural-language-inference-bert.md|d2l-ai|d2l-zh|natural-language-inference-bert.md|Markdown|398|0|72
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/gd.md|d2l-ai|d2l-zh|gd.md|Markdown|397|0|109
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preface/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|397|0|65
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/bert-dataset.md|d2l-ai|d2l-zh|bert-dataset.md|Markdown|395|0|53
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/rec-caser.svg|d2l-ai|d2l-zh|rec-caser.svg|SVG|394|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/anchor-label.svg|d2l-ai|d2l-zh|anchor-label.svg|SVG|392|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/semantic-segmentation-and-dataset_origin.md|d2l-ai|d2l-zh|semantic-segmentation-and-dataset_origin.md|Markdown|390|0|73
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/linear-regression-scratch_origin.md|d2l-ai|d2l-zh|linear-regression-scratch_origin.md|Markdown|388|0|70
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/language-models-and-dataset.md|d2l-ai|d2l-zh|language-models-and-dataset.md|Markdown|388|0|76
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/attention-scoring-functions_origin.md|d2l-ai|d2l-zh|attention-scoring-functions_origin.md|Markdown|387|0|62
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/fcn_origin.md|d2l-ai|d2l-zh|fcn_origin.md|Markdown|381|0|69
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/bert-dataset_origin.md|d2l-ai|d2l-zh|bert-dataset_origin.md|Markdown|381|0|47
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/nadaraya-waston_origin.md|d2l-ai|d2l-zh|nadaraya-waston_origin.md|Markdown|380|0|86
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/googlenet.md|d2l-ai|d2l-zh|googlenet.md|Markdown|380|0|67
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/googlenet_origin.md|d2l-ai|d2l-zh|googlenet_origin.md|Markdown|380|0|58
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/environment.md|d2l-ai|d2l-zh|environment.md|Markdown|376|0|101
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/autograd.md|d2l-ai|d2l-zh|autograd.md|Markdown|376|0|83
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/hybridize.md|d2l-ai|d2l-zh|hybridize.md|Markdown|372|0|103
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/resnet_origin.md|d2l-ai|d2l-zh|resnet_origin.md|Markdown|372|0|72
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/multihead-attention.md|d2l-ai|d2l-zh|multihead-attention.md|Markdown|371|0|69
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/rec-seq-data.svg|d2l-ai|d2l-zh|rec-seq-data.svg|SVG|369|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/rec-ranking.svg|d2l-ai|d2l-zh|rec-ranking.svg|SVG|368|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/language-models-and-dataset_origin.md|d2l-ai|d2l-zh|language-models-and-dataset_origin.md|Markdown|364|0|77
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/image-augmentation_origin.md|d2l-ai|d2l-zh|image-augmentation_origin.md|Markdown|363|0|76
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/natural-language-inference-attention_origin.md|d2l-ai|d2l-zh|natural-language-inference-attention_origin.md|Markdown|363|0|84
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/resnet18.svg|d2l-ai|d2l-zh|resnet18.svg|SVG|363|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/falseshare.svg|d2l-ai|d2l-zh|falseshare.svg|SVG|362|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/inception.svg|d2l-ai|d2l-zh|inception.svg|SVG|360|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/a77.svg|d2l-ai|d2l-zh|a77.svg|SVG|359|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/fine-tuning.md|d2l-ai|d2l-zh|fine-tuning.md|Markdown|356|0|80
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/sentiment-analysis-cnn_origin.md|d2l-ai|d2l-zh|sentiment-analysis-cnn_origin.md|Markdown|356|0|67
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/deep-rnn.svg|d2l-ai|d2l-zh|deep-rnn.svg|SVG|355|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/threading.svg|d2l-ai|d2l-zh|threading.svg|SVG|353|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/linear-regression-scratch.md|d2l-ai|d2l-zh|linear-regression-scratch.md|Markdown|352|0|68
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/bptt_origin.md|d2l-ai|d2l-zh|bptt_origin.md|Markdown|350|0|77
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/momentum.md|d2l-ai|d2l-zh|momentum.md|Markdown|348|0|98
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/resnet-block.svg|d2l-ai|d2l-zh|resnet-block.svg|SVG|348|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/cnn-rnn-self-attention.svg|d2l-ai|d2l-zh|cnn-rnn-self-attention.svg|SVG|347|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/autograd_origin.md|d2l-ai|d2l-zh|autograd_origin.md|Markdown|346|0|70
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/trans_conv_stride2.svg|d2l-ai|d2l-zh|trans_conv_stride2.svg|SVG|346|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/gru-2.svg|d2l-ai|d2l-zh|gru-2.svg|SVG|345|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/multiple-gpus_origin.md|d2l-ai|d2l-zh|multiple-gpus_origin.md|Markdown|343|0|71
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/rec-neumf.svg|d2l-ai|d2l-zh|rec-neumf.svg|SVG|343|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/sequence_origin.md|d2l-ai|d2l-zh|sequence_origin.md|Markdown|342|0|82
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/ps.svg|d2l-ai|d2l-zh|ps.svg|SVG|342|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/natural-language-inference-bert_origin.md|d2l-ai|d2l-zh|natural-language-inference-bert_origin.md|Markdown|340|0|55
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/bert-two-seqs.svg|d2l-ai|d2l-zh|bert-two-seqs.svg|SVG|340|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/softmax-regression_origin.md|d2l-ai|d2l-zh|softmax-regression_origin.md|Markdown|338|0|78
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/nlp-map-app.svg|d2l-ai|d2l-zh|nlp-map-app.svg|SVG|336|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/nlp-map-nli-attention.svg|d2l-ai|d2l-zh|nlp-map-nli-attention.svg|SVG|336|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/nlp-map-nli-bert.svg|d2l-ai|d2l-zh|nlp-map-nli-bert.svg|SVG|336|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/nlp-map-pretrain.svg|d2l-ai|d2l-zh|nlp-map-pretrain.svg|SVG|336|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/nlp-map-sa-cnn.svg|d2l-ai|d2l-zh|nlp-map-sa-cnn.svg|SVG|336|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/nlp-map-sa-rnn.svg|d2l-ai|d2l-zh|nlp-map-sa-rnn.svg|SVG|336|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/image-classification-dataset.md|d2l-ai|d2l-zh|image-classification-dataset.md|Markdown|334|0|64
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/probability_origin.md|d2l-ai|d2l-zh|probability_origin.md|Markdown|334|0|108
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/dropout2.svg|d2l-ai|d2l-zh|dropout2.svg|SVG|334|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/conv-stride.svg|d2l-ai|d2l-zh|conv-stride.svg|SVG|333|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/marginal.svg|d2l-ai|d2l-zh|marginal.svg|SVG|333|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/word-embedding-dataset.md|d2l-ai|d2l-zh|word-embedding-dataset.md|Markdown|328|0|77
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/bert-pretraining.md|d2l-ai|d2l-zh|bert-pretraining.md|Markdown|326|0|46
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/word2vec-pretraining.md|d2l-ai|d2l-zh|word2vec-pretraining.md|Markdown|324|0|70
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/densenet_origin.md|d2l-ai|d2l-zh|densenet_origin.md|Markdown|323|0|74
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/self-attention-and-positional-encoding.md|d2l-ai|d2l-zh|self-attention-and-positional-encoding.md|Markdown|322|0|60
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/lstm-1.svg|d2l-ai|d2l-zh|lstm-1.svg|SVG|322|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/rnn-concise.md|d2l-ai|d2l-zh|rnn-concise.md|Markdown|321|0|60
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/rec-intro.svg|d2l-ai|d2l-zh|rec-intro.svg|SVG|321|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/rnn-train.svg|d2l-ai|d2l-zh|rnn-train.svg|SVG|321|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/bert-one-seq.svg|d2l-ai|d2l-zh|bert-one-seq.svg|SVG|318|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/bahdanau-attention_origin.md|d2l-ai|d2l-zh|bahdanau-attention_origin.md|Markdown|315|0|47
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/multiple-gpus-concise.md|d2l-ai|d2l-zh|multiple-gpus-concise.md|Markdown|315|0|49
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/attention-output.svg|d2l-ai|d2l-zh|attention-output.svg|SVG|311|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/finetune.svg|d2l-ai|d2l-zh|finetune.svg|SVG|311|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/hybridize_origin.md|d2l-ai|d2l-zh|hybridize_origin.md|Markdown|310|0|96
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/machine-translation-and-dataset_origin.md|d2l-ai|d2l-zh|machine-translation-and-dataset_origin.md|Markdown|310|0|46
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/self-attention-and-positional-encoding_origin.md|d2l-ai|d2l-zh|self-attention-and-positional-encoding_origin.md|Markdown|309|0|53
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/conv-layer.md|d2l-ai|d2l-zh|conv-layer.md|Markdown|309|0|79
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/word2vec-pretraining_origin.md|d2l-ai|d2l-zh|word2vec-pretraining_origin.md|Markdown|308|0|60
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/numerical-stability-and-init_origin.md|d2l-ai|d2l-zh|numerical-stability-and-init_origin.md|Markdown|307|0|68
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/self-attention.svg|d2l-ai|d2l-zh|self-attention.svg|SVG|300|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/seq2seq.svg|d2l-ai|d2l-zh|seq2seq.svg|SVG|297|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/sentiment-analysis-cnn.md|d2l-ai|d2l-zh|sentiment-analysis-cnn.md|Markdown|294|0|70
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/fine-tuning_origin.md|d2l-ai|d2l-zh|fine-tuning_origin.md|Markdown|292|0|81
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/convexity.md|d2l-ai|d2l-zh|convexity.md|Markdown|290|0|111
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/gru_origin.md|d2l-ai|d2l-zh|gru_origin.md|Markdown|285|0|71
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/contribute.svg|d2l-ai|d2l-zh|contribute.svg|SVG|283|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/transposed-conv_origin.md|d2l-ai|d2l-zh|transposed-conv_origin.md|Markdown|280|0|55
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/why-conv_origin.md|d2l-ai|d2l-zh|why-conv_origin.md|Markdown|280|0|59
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/bert-pretraining_origin.md|d2l-ai|d2l-zh|bert-pretraining_origin.md|Markdown|277|0|36
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/padding-and-strides_origin.md|d2l-ai|d2l-zh|padding-and-strides_origin.md|Markdown|276|0|48
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/natural-language-inference-and-dataset.md|d2l-ai|d2l-zh|natural-language-inference-and-dataset.md|Markdown|276|0|64
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/chapter_natural-language-processing/machine-translation.md|d2l-ai|d2l-zh|machine-translation.md|Markdown|274|0|75
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/bw-hierarchy.svg|d2l-ai|d2l-zh|bw-hierarchy.svg|SVG|274|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/alexnet.md|d2l-ai|d2l-zh|alexnet.md|Markdown|272|0|62
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/rnn.md|d2l-ai|d2l-zh|rnn.md|Markdown|272|0|59
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/beam-search.svg|d2l-ai|d2l-zh|beam-search.svg|SVG|272|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/lang-model-data.svg|d2l-ai|d2l-zh|lang-model-data.svg|SVG|271|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/calculus_origin.md|d2l-ai|d2l-zh|calculus_origin.md|Markdown|270|0|84
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/timemachine-5gram.svg|d2l-ai|d2l-zh|timemachine-5gram.svg|SVG|270|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/trans_conv.svg|d2l-ai|d2l-zh|trans_conv.svg|SVG|269|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/adam.md|d2l-ai|d2l-zh|adam.md|Markdown|266|0|57
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/seq2seq-predict.svg|d2l-ai|d2l-zh|seq2seq-predict.svg|SVG|266|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/read-write.md|d2l-ai|d2l-zh|read-write.md|Markdown|264|0|62
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/convexity_origin.md|d2l-ai|d2l-zh|convexity_origin.md|Markdown|263|0|114
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/lstm-0.svg|d2l-ai|d2l-zh|lstm-0.svg|SVG|262|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/pooling_origin.md|d2l-ai|d2l-zh|pooling_origin.md|Markdown|261|0|57
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/bptt.md|d2l-ai|d2l-zh|bptt.md|Markdown|261|0|62
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/rnn-bptt.svg|d2l-ai|d2l-zh|rnn-bptt.svg|SVG|261|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/neuron.svg|d2l-ai|d2l-zh|neuron.svg|SVG|260|1|8
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/pooling.md|d2l-ai|d2l-zh|pooling.md|Markdown|257|0|66
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/multihead-attention_origin.md|d2l-ai|d2l-zh|multihead-attention_origin.md|Markdown|256|0|53
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/softmax-regression.md|d2l-ai|d2l-zh|softmax-regression.md|Markdown|255|0|69
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/machine-translation-and-dataset.md|d2l-ai|d2l-zh|machine-translation-and-dataset.md|Markdown|255|0|46
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/conv1d-2d.svg|d2l-ai|d2l-zh|conv1d-2d.svg|SVG|254|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/conv1d-channel.svg|d2l-ai|d2l-zh|conv1d-channel.svg|SVG|254|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/rnn.svg|d2l-ai|d2l-zh|rnn.svg|SVG|254|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/custom-layer.md|d2l-ai|d2l-zh|custom-layer.md|Markdown|253|0|64
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/mobo-symbol.svg|d2l-ai|d2l-zh|mobo-symbol.svg|SVG|252|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/sum-order.svg|d2l-ai|d2l-zh|sum-order.svg|SVG|252|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/adagrad.md|d2l-ai|d2l-zh|adagrad.md|Markdown|251|0|64
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/sentiment-analysis-rnn.md|d2l-ai|d2l-zh|sentiment-analysis-rnn.md|Markdown|249|0|49
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/lstm_origin.md|d2l-ai|d2l-zh|lstm_origin.md|Markdown|248|0|76
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/calculus.md|d2l-ai|d2l-zh|calculus.md|Markdown|247|0|77
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/bi-rnn.md|d2l-ai|d2l-zh|bi-rnn.md|Markdown|247|0|54
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/gan.svg|d2l-ai|d2l-zh|gan.svg|SVG|246|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/momentum_origin.md|d2l-ai|d2l-zh|momentum_origin.md|Markdown|244|0|92
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/gd_origin.md|d2l-ai|d2l-zh|gd_origin.md|Markdown|243|0|105
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/multiple-gpus-concise_origin.md|d2l-ai|d2l-zh|multiple-gpus-concise_origin.md|Markdown|242|0|44
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/image-classification-dataset_origin.md|d2l-ai|d2l-zh|image-classification-dataset_origin.md|Markdown|242|0|52
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/similarity-analogy_origin.md|d2l-ai|d2l-zh|similarity-analogy_origin.md|Markdown|241|0|53
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/backprop_origin.md|d2l-ai|d2l-zh|backprop_origin.md|Markdown|240|0|56
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/numerical-stability-and-init.md|d2l-ai|d2l-zh|numerical-stability-and-init.md|Markdown|239|0|60
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/object-detection-dataset.md|d2l-ai|d2l-zh|object-detection-dataset.md|Markdown|237|0|42
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/transposed-conv.md|d2l-ai|d2l-zh|transposed-conv.md|Markdown|234|0|57
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/channels_origin.md|d2l-ai|d2l-zh|channels_origin.md|Markdown|234|0|47
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/neural-style.svg|d2l-ai|d2l-zh|neural-style.svg|SVG|234|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/natural-language-inference-and-dataset_origin.md|d2l-ai|d2l-zh|natural-language-inference-and-dataset_origin.md|Markdown|233|0|57
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/glove_origin.md|d2l-ai|d2l-zh|glove_origin.md|Markdown|233|0|52
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/faster-rcnn.svg|d2l-ai|d2l-zh|faster-rcnn.svg|SVG|233|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/vgg_origin.md|d2l-ai|d2l-zh|vgg_origin.md|Markdown|231|0|45
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/rcnn_origin.md|d2l-ai|d2l-zh|rcnn_origin.md|Markdown|230|0|67
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/sentiment-analysis-rnn_origin.md|d2l-ai|d2l-zh|sentiment-analysis-rnn_origin.md|Markdown|229|0|43
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/mlp.svg|d2l-ai|d2l-zh|mlp.svg|SVG|229|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/gru-1.svg|d2l-ai|d2l-zh|gru-1.svg|SVG|228|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/read-write_origin.md|d2l-ai|d2l-zh|read-write_origin.md|Markdown|227|0|51
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/birnn.svg|d2l-ai|d2l-zh|birnn.svg|SVG|227|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/vgg.md|d2l-ai|d2l-zh|vgg.md|Markdown|226|0|54
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/mlp-scratch.md|d2l-ai|d2l-zh|mlp-scratch.md|Markdown|225|0|54
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/rnn_origin.md|d2l-ai|d2l-zh|rnn_origin.md|Markdown|224|0|61
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/sequence-model.svg|d2l-ai|d2l-zh|sequence-model.svg|SVG|222|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/custom-layer_origin.md|d2l-ai|d2l-zh|custom-layer_origin.md|Markdown|221|0|54
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/async-computation.md|d2l-ai|d2l-zh|async-computation.md|Markdown|220|0|62
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/residual-block.svg|d2l-ai|d2l-zh|residual-block.svg|SVG|219|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/neon128.svg|d2l-ai|d2l-zh|neon128.svg|SVG|213|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/auto-parallelism.md|d2l-ai|d2l-zh|auto-parallelism.md|Markdown|212|0|60
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/object-detection-dataset_origin.md|d2l-ai|d2l-zh|object-detection-dataset_origin.md|Markdown|211|0|36
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/rnn-concise_origin.md|d2l-ai|d2l-zh|rnn-concise_origin.md|Markdown|211|0|38
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/functionclasses.svg|d2l-ai|d2l-zh|functionclasses.svg|SVG|209|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/nin.md|d2l-ai|d2l-zh|nin.md|Markdown|208|0|36
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/encoder-decoder.md|d2l-ai|d2l-zh|encoder-decoder.md|Markdown|208|0|49
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/roi.svg|d2l-ai|d2l-zh|roi.svg|SVG|206|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/subword-embedding_origin.md|d2l-ai|d2l-zh|subword-embedding_origin.md|Markdown|205|0|39
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/s2s-prob1.svg|d2l-ai|d2l-zh|s2s-prob1.svg|SVG|205|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/s2s-prob2.svg|d2l-ai|d2l-zh|s2s-prob2.svg|SVG|205|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/mlp-scratch_origin.md|d2l-ai|d2l-zh|mlp-scratch_origin.md|Markdown|204|0|47
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/data-parallel.svg|d2l-ai|d2l-zh|data-parallel.svg|SVG|203|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/attention-cues_origin.md|d2l-ai|d2l-zh|attention-cues_origin.md|Markdown|202|0|36
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/nin_origin.md|d2l-ai|d2l-zh|nin_origin.md|Markdown|202|0|32
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/forward.svg|d2l-ai|d2l-zh|forward.svg|SVG|202|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/similarity-analogy.md|d2l-ai|d2l-zh|similarity-analogy.md|Markdown|200|0|54
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/rmsprop.md|d2l-ai|d2l-zh|rmsprop.md|Markdown|200|0|44
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/sgd_origin.md|d2l-ai|d2l-zh|sgd_origin.md|Markdown|200|0|89
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/padding-and-strides.md|d2l-ai|d2l-zh|padding-and-strides.md|Markdown|197|0|55
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/seq2seq-attention-details.svg|d2l-ai|d2l-zh|seq2seq-attention-details.svg|SVG|195|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/sentiment-analysis-and-dataset_origin.md|d2l-ai|d2l-zh|sentiment-analysis-and-dataset_origin.md|Markdown|194|0|38
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/ssd.svg|d2l-ai|d2l-zh|ssd.svg|SVG|194|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/approx-training_origin.md|d2l-ai|d2l-zh|approx-training_origin.md|Markdown|193|0|45
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.md|d2l-ai|d2l-zh|sentiment-analysis-and-dataset.md|Markdown|191|0|39
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/frontends.svg|d2l-ai|d2l-zh|frontends.svg|SVG|190|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/async-computation_origin.md|d2l-ai|d2l-zh|async-computation_origin.md|Markdown|188|0|56
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/text-preprocessing.md|d2l-ai|d2l-zh|text-preprocessing.md|Markdown|188|0|41
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/optimization-intro_origin.md|d2l-ai|d2l-zh|optimization-intro_origin.md|Markdown|186|0|45
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/config.ini|d2l-ai|d2l-zh|config.ini|INI|186|0|70
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/multiscale-object-detection_origin.md|d2l-ai|d2l-zh|multiscale-object-detection_origin.md|Markdown|185|0|38
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/adam_origin.md|d2l-ai|d2l-zh|adam_origin.md|Markdown|184|0|51
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/mask-rcnn.svg|d2l-ai|d2l-zh|mask-rcnn.svg|SVG|184|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/optimization-intro.md|d2l-ai|d2l-zh|optimization-intro.md|Markdown|183|0|50
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/sgd.md|d2l-ai|d2l-zh|sgd.md|Markdown|183|0|79
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/hi-softmax.svg|d2l-ai|d2l-zh|hi-softmax.svg|SVG|183|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/word2vec_origin.md|d2l-ai|d2l-zh|word2vec_origin.md|Markdown|182|0|80
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/bi-rnn_origin.md|d2l-ai|d2l-zh|bi-rnn_origin.md|Markdown|182|0|61
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/multi-head-attention.svg|d2l-ai|d2l-zh|multi-head-attention.svg|SVG|181|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/style-transfer.svg|d2l-ai|d2l-zh|style-transfer.svg|SVG|181|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/correlation.svg|d2l-ai|d2l-zh|correlation.svg|SVG|180|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/computegraph.svg|d2l-ai|d2l-zh|computegraph.svg|SVG|179|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/qkv.svg|d2l-ai|d2l-zh|qkv.svg|SVG|179|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/rect-trans.svg|d2l-ai|d2l-zh|rect-trans.svg|SVG|179|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/beam-search_origin.md|d2l-ai|d2l-zh|beam-search_origin.md|Markdown|178|0|39
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/attention.svg|d2l-ai|d2l-zh|attention.svg|SVG|177|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/aws_origin.md|d2l-ai|d2l-zh|aws_origin.md|Markdown|176|0|90
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/softmax-regression-concise.md|d2l-ai|d2l-zh|softmax-regression-concise.md|Markdown|176|0|47
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/softmax-regression-concise_origin.md|d2l-ai|d2l-zh|softmax-regression-concise_origin.md|Markdown|175|0|41
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/ci/docker/git-timesync|d2l-ai|d2l-zh|git-timesync|Bourne Shell|175|81|32
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/pooling.svg|d2l-ai|d2l-zh|pooling.svg|SVG|175|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/singlelayer.svg|d2l-ai|d2l-zh|singlelayer.svg|SVG|175|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/text-preprocessing_origin.md|d2l-ai|d2l-zh|text-preprocessing_origin.md|Markdown|174|0|35
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/ci/submit-job.py|d2l-ai|d2l-zh|submit-job.py|Python|172|2|28
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/seq2seq-details.svg|d2l-ai|d2l-zh|seq2seq-details.svg|SVG|171|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preface/index.md|d2l-ai|d2l-zh|index.md|Markdown|167|0|52
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/fast-rcnn.svg|d2l-ai|d2l-zh|fast-rcnn.svg|SVG|167|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/asyncgraph.svg|d2l-ai|d2l-zh|asyncgraph.svg|SVG|166|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/STYLE_GUIDE.md|d2l-ai|d2l-zh|STYLE_GUIDE.md|Markdown|165|0|13
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/chapter_natural-language-processing/sentiment-analysis-rnn.md|d2l-ai|d2l-zh|sentiment-analysis-rnn.md|Markdown|163|0|63
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/adagrad_origin.md|d2l-ai|d2l-zh|adagrad_origin.md|Markdown|162|0|61
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/conv-1x1.svg|d2l-ai|d2l-zh|conv-1x1.svg|SVG|160|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/hardware_origin.md|d2l-ai|d2l-zh|hardware_origin.md|Markdown|159|0|73
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/finetuning-bert_origin.md|d2l-ai|d2l-zh|finetuning-bert_origin.md|Markdown|159|0|35
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/attention-cues.md|d2l-ai|d2l-zh|attention-cues.md|Markdown|158|0|34
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/adadelta.md|d2l-ai|d2l-zh|adadelta.md|Markdown|158|0|42
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/conv1d.svg|d2l-ai|d2l-zh|conv1d.svg|SVG|158|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/encoder-decoder_origin.md|d2l-ai|d2l-zh|encoder-decoder_origin.md|Markdown|157|0|34
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/hardware.md|d2l-ai|d2l-zh|hardware.md|Markdown|151|0|66
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/auto-parallelism_origin.md|d2l-ai|d2l-zh|auto-parallelism_origin.md|Markdown|150|0|50
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/channels.md|d2l-ai|d2l-zh|channels.md|Markdown|149|0|46
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_installation/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|149|0|73
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/bounding-box_origin.md|d2l-ai|d2l-zh|bounding-box_origin.md|Markdown|148|0|32
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/fcn.svg|d2l-ai|d2l-zh|fcn.svg|SVG|148|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/rmsprop_origin.md|d2l-ai|d2l-zh|rmsprop_origin.md|Markdown|147|0|40
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/densenet.svg|d2l-ai|d2l-zh|densenet.svg|SVG|142|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/multiscale-object-detection.md|d2l-ai|d2l-zh|multiscale-object-detection.md|Markdown|141|0|37
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/TERMINOLOGY.md|d2l-ai|d2l-zh|TERMINOLOGY.md|Markdown|139|0|138
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_installation/index.md|d2l-ai|d2l-zh|index.md|Markdown|139|0|89
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/chapter_natural-language-processing/sentiment-analysis-cnn.md|d2l-ai|d2l-zh|sentiment-analysis-cnn.md|Markdown|139|0|58
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/rec-mf.svg|d2l-ai|d2l-zh|rec-mf.svg|SVG|139|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/deep-rnn.md|d2l-ai|d2l-zh|deep-rnn.md|Markdown|138|0|36
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/beam-search.md|d2l-ai|d2l-zh|beam-search.md|Markdown|137|0|32
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/aws.md|d2l-ai|d2l-zh|aws.md|Markdown|136|0|69
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/backprop.md|d2l-ai|d2l-zh|backprop.md|Markdown|136|0|47
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/.github/workflows/ci.yml|d2l-ai|d2l-zh|ci.yml|YAML|133|1|8
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/rcnn.md|d2l-ai|d2l-zh|rcnn.md|Markdown|133|0|49
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/chapter_recommender-systems/mf.md|d2l-ai|d2l-zh|mf.md|Markdown|133|0|36
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/deferred-init_origin.md|d2l-ai|d2l-zh|deferred-init_origin.md|Markdown|132|0|32
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/eye-book.svg|d2l-ai|d2l-zh|eye-book.svg|SVG|132|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/softmaxreg.svg|d2l-ai|d2l-zh|softmaxreg.svg|SVG|131|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/space-division.svg|d2l-ai|d2l-zh|space-division.svg|SVG|131|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/subword-embedding.md|d2l-ai|d2l-zh|subword-embedding.md|Markdown|128|0|40
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/bounding-box.md|d2l-ai|d2l-zh|bounding-box.md|Markdown|127|0|31
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/data-collection.svg|d2l-ai|d2l-zh|data-collection.svg|SVG|127|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/chapter_recommender-systems/movielens.md|d2l-ai|d2l-zh|movielens.md|Markdown|125|0|29
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/sagemaker_origin.md|d2l-ai|d2l-zh|sagemaker_origin.md|Markdown|124|0|47
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/copyto.svg|d2l-ai|d2l-zh|copyto.svg|SVG|123|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/adadelta_origin.md|d2l-ai|d2l-zh|adadelta_origin.md|Markdown|122|0|39
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/eye-coffee.svg|d2l-ai|d2l-zh|eye-coffee.svg|SVG|122|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/proj-vec.svg|d2l-ai|d2l-zh|proj-vec.svg|SVG|121|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/deep-rnn_origin.md|d2l-ai|d2l-zh|deep-rnn_origin.md|Markdown|119|0|34
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/contributing.md|d2l-ai|d2l-zh|contributing.md|Markdown|118|0|43
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/mlp-concise.md|d2l-ai|d2l-zh|mlp-concise.md|Markdown|117|0|29
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/hmm.svg|d2l-ai|d2l-zh|hmm.svg|SVG|117|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/truncated-bptt.svg|d2l-ai|d2l-zh|truncated-bptt.svg|SVG|116|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/grid-transform-filled.svg|d2l-ai|d2l-zh|grid-transform-filled.svg|SVG|115|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/grid-transform.svg|d2l-ai|d2l-zh|grid-transform.svg|SVG|113|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/capacity-vs-error.svg|d2l-ai|d2l-zh|capacity-vs-error.svg|SVG|111|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/ml-loop.svg|d2l-ai|d2l-zh|ml-loop.svg|SVG|111|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/supervised-learning.svg|d2l-ai|d2l-zh|supervised-learning.svg|SVG|111|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/negSecDer.svg|d2l-ai|d2l-zh|negSecDer.svg|SVG|110|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/posSecDer.svg|d2l-ai|d2l-zh|posSecDer.svg|SVG|110|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/zeroSecDer.svg|d2l-ai|d2l-zh|zeroSecDer.svg|SVG|109|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/pandas.md|d2l-ai|d2l-zh|pandas.md|Markdown|107|0|33
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/cbow.svg|d2l-ai|d2l-zh|cbow.svg|SVG|107|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/why-conv.md|d2l-ai|d2l-zh|why-conv.md|Markdown|106|0|45
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/chain-net1.svg|d2l-ai|d2l-zh|chain-net1.svg|SVG|103|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/space-division-3d.svg|d2l-ai|d2l-zh|space-division-3d.svg|SVG|103|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/deferred-init.md|d2l-ai|d2l-zh|deferred-init.md|Markdown|102|0|31
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/pandas_origin.md|d2l-ai|d2l-zh|pandas_origin.md|Markdown|102|0|32
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/jupyter_origin.md|d2l-ai|d2l-zh|jupyter_origin.md|Markdown|101|0|55
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/singleneuron.svg|d2l-ai|d2l-zh|singleneuron.svg|SVG|101|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/mlp-concise_origin.md|d2l-ai|d2l-zh|mlp-concise_origin.md|Markdown|99|0|23
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/lookup-api.md|d2l-ai|d2l-zh|lookup-api.md|Markdown|99|0|30
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/frontends/Canvas 1.svg|d2l-ai|d2l-zh|Canvas 1.svg|SVG|99|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/skip-gram.svg|d2l-ai|d2l-zh|skip-gram.svg|SVG|95|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/chapter_natural-language-processing/similarity-analogy.md|d2l-ai|d2l-zh|similarity-analogy.md|Markdown|94|0|50
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/vec-add.svg|d2l-ai|d2l-zh|vec-add.svg|SVG|92|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/chapter_recommender-systems/autorec.md|d2l-ai|d2l-zh|autorec.md|Markdown|91|0|27
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/rl-environment.svg|d2l-ai|d2l-zh|rl-environment.svg|SVG|90|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/encoder-decoder.svg|d2l-ai|d2l-zh|encoder-decoder.svg|SVG|87|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/vec-angle.svg|d2l-ai|d2l-zh|vec-angle.svg|SVG|85|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/capacity_vs_error.svg|d2l-ai|d2l-zh|capacity_vs_error.svg|SVG|84|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/sagemaker.md|d2l-ai|d2l-zh|sagemaker.md|Markdown|83|0|41
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/.github/actions/submit-job/action.yml|d2l-ai|d2l-zh|action.yml|YAML|82|2|7
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/chapter_recommender-systems/fm.md|d2l-ai|d2l-zh|fm.md|Markdown|82|0|26
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/wake-word.svg|d2l-ai|d2l-zh|wake-word.svg|SVG|82|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/grid-points.svg|d2l-ai|d2l-zh|grid-points.svg|SVG|81|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/d2lzh/text/embedding.py|d2l-ai|d2l-zh|embedding.py|Python|80|5|10
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/contributing_origin.md|d2l-ai|d2l-zh|contributing_origin.md|Markdown|79|0|50
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/chain-net2.svg|d2l-ai|d2l-zh|chain-net2.svg|SVG|77|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/.github/workflows/build-docker.yml|d2l-ai|d2l-zh|build-docker.yml|YAML|76|4|8
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/static/post_latex/main.py|d2l-ai|d2l-zh|main.py|Python|76|14|20
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/chapter_recommender-systems/ctr.md|d2l-ai|d2l-zh|ctr.md|Markdown|75|0|24
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/iou.svg|d2l-ai|d2l-zh|iou.svg|SVG|75|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/lookup-api_origin.md|d2l-ai|d2l-zh|lookup-api_origin.md|Markdown|74|0|29
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/densenet-block.svg|d2l-ai|d2l-zh|densenet-block.svg|SVG|73|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/jupyter.md|d2l-ai|d2l-zh|jupyter.md|Markdown|72|0|40
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/parameterserver_origin.md|d2l-ai|d2l-zh|parameterserver_origin.md|Markdown|72|0|47
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|71|0|7
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/word2vec.md|d2l-ai|d2l-zh|word2vec.md|Markdown|71|0|53
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/par-vec.svg|d2l-ai|d2l-zh|par-vec.svg|SVG|69|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/parameterserver.md|d2l-ai|d2l-zh|parameterserver.md|Markdown|63|0|40
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/add_norm.svg|d2l-ai|d2l-zh|add_norm.svg|SVG|62|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/d2l.md|d2l-ai|d2l-zh|d2l.md|Markdown|61|0|25
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|61|0|7
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/glove.md|d2l-ai|d2l-zh|glove.md|Markdown|60|0|37
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/cat-dog-test.svg|d2l-ai|d2l-zh|cat-dog-test.svg|SVG|60|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/cat-dog-train.svg|d2l-ai|d2l-zh|cat-dog-train.svg|SVG|60|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_notation/index.md|d2l-ai|d2l-zh|index.md|Markdown|59|0|14
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_notation/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|59|0|25
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|57|0|13
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/README.md|d2l-ai|d2l-zh|README.md|Markdown|56|0|26
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/d2l_origin.md|d2l-ai|d2l-zh|d2l_origin.md|Markdown|55|0|43
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|55|0|9
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|55|0|6
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/INFO.md|d2l-ai|d2l-zh|INFO.md|Markdown|54|0|28
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/approx-training.md|d2l-ai|d2l-zh|approx-training.md|Markdown|53|0|34
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|51|0|9
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|46|0|6
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/index.md|d2l-ai|d2l-zh|index.md|Markdown|46|0|8
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-pretraining/index.md|d2l-ai|d2l-zh|index.md|Markdown|46|0|9
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/segmentation.svg|d2l-ai|d2l-zh|segmentation.svg|SVG|45|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/.github/actions/setup_env_vars/action.yml|d2l-ai|d2l-zh|action.yml|YAML|44|0|13
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|44|0|6
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/sub-area.svg|d2l-ai|d2l-zh|sub-area.svg|SVG|43|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/selecting-servers-gpus_origin.md|d2l-ai|d2l-zh|selecting-servers-gpus_origin.md|Markdown|42|0|28
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/ci/docker/d2l_job.sh|d2l-ai|d2l-zh|d2l_job.sh|Bourne Shell|42|14|12
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_natural-language-processing-applications/finetuning-bert.md|d2l-ai|d2l-zh|finetuning-bert.md|Markdown|41|0|26
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.md|d2l-ai|d2l-zh|selecting-servers-gpus.md|Markdown|40|0|21
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|38|0|6
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/index.md|d2l-ai|d2l-zh|index.md|Markdown|36|0|7
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/index.md|d2l-ai|d2l-zh|index.md|Markdown|36|0|13
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/.github/workflows/clear-cache.yml|d2l-ai|d2l-zh|clear-cache.yml|YAML|35|0|4
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-modern/index.md|d2l-ai|d2l-zh|index.md|Markdown|35|0|5
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|34|0|4
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_attention-mechanisms/index.md|d2l-ai|d2l-zh|index.md|Markdown|32|0|7
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_deep-learning-computation/index.md|d2l-ai|d2l-zh|index.md|Markdown|32|0|4
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_preliminaries/index.md|d2l-ai|d2l-zh|index.md|Markdown|32|0|8
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/ci/docker/print_versions.py|d2l-ai|d2l-zh|print_versions.py|Python|32|8|11
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/fit-linreg.svg|d2l-ai|d2l-zh|fit-linreg.svg|SVG|31|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computer-vision/index.md|d2l-ai|d2l-zh|index.md|Markdown|28|0|4
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-neural-networks/index.md|d2l-ai|d2l-zh|index.md|Markdown|28|0|6
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|28|0|6
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_recurrent-neural-networks/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|27|0|8
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/convex-intersect.svg|d2l-ai|d2l-zh|convex-intersect.svg|SVG|27|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_multilayer-perceptrons/index.md|d2l-ai|d2l-zh|index.md|Markdown|26|0|3
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/static/cache.sh|d2l-ai|d2l-zh|cache.sh|Bourne Shell|26|0|3
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_convolutional-modern/index.md|d2l-ai|d2l-zh|index.md|Markdown|25|0|6
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/.github/workflow_scripts/build_pytorch.sh|d2l-ai|d2l-zh|build_pytorch.sh|Bourne Shell|24|7|10
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/.github/workflow_scripts/build_and_deploy.sh|d2l-ai|d2l-zh|build_and_deploy.sh|Bourne Shell|23|8|14
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/.github/workflow_scripts/build_tf.sh|d2l-ai|d2l-zh|build_tf.sh|Bourne Shell|22|7|10
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/setup.py|d2l-ai|d2l-zh|setup.py|Python|22|0|2
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/.github/workflow_scripts/build_mxnet.sh|d2l-ai|d2l-zh|build_mxnet.sh|Bourne Shell|21|13|10
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|21|0|4
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/.github/workflow_scripts/build_paddle.sh|d2l-ai|d2l-zh|build_paddle.sh|Bourne Shell|20|7|10
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|20|0|3
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/index_origin.md|d2l-ai|d2l-zh|index_origin.md|Markdown|19|0|5
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_optimization/index.md|d2l-ai|d2l-zh|index.md|Markdown|19|0|5
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/ci/docker/Dockerfile.d2l-builder|d2l-ai|d2l-zh|Dockerfile.d2l-builder|Dockerfile|19|8|12
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/chapter_recommender-systems/index.md|d2l-ai|d2l-zh|index.md|Markdown|19|0|7
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/d2lzh/text/vocab.py|d2l-ai|d2l-zh|vocab.py|Python|19|1|2
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/projections.svg|d2l-ai|d2l-zh|projections.svg|SVG|19|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_computational-performance/index.md|d2l-ai|d2l-zh|index.md|Markdown|18|0|3
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_linear-networks/index.md|d2l-ai|d2l-zh|index.md|Markdown|18|0|3
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/.github/workflow_scripts/build_html.sh|d2l-ai|d2l-zh|build_html.sh|Bourne Shell|17|3|4
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/pacman.svg|d2l-ai|d2l-zh|pacman.svg|SVG|17|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/static/build.yml|d2l-ai|d2l-zh|build.yml|YAML|16|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/mutual-information.svg|d2l-ai|d2l-zh|mutual-information.svg|SVG|15|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/r-cnn.svg|d2l-ai|d2l-zh|r-cnn.svg|SVG|15|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/ci/docker/Dockerfile.d2l-zh-mxnet|d2l-ai|d2l-zh|Dockerfile.d2l-zh-mxnet|Dockerfile|14|7|10
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/ci/docker/Dockerfile.d2l-zh-paddle|d2l-ai|d2l-zh|Dockerfile.d2l-zh-paddle|Dockerfile|14|7|10
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/nonconvex.svg|d2l-ai|d2l-zh|nonconvex.svg|SVG|14|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_appendix-tools-for-deep-learning/index.md|d2l-ai|d2l-zh|index.md|Markdown|13|0|3
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/ci/docker/Dockerfile.d2l-zh-tf|d2l-ai|d2l-zh|Dockerfile.d2l-zh-tf|Dockerfile|13|6|9
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/ci/docker/Dockerfile.d2l-zh-torch|d2l-ai|d2l-zh|Dockerfile.d2l-zh-torch|Dockerfile|13|6|9
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/polygon-circle.svg|d2l-ai|d2l-zh|polygon-circle.svg|SVG|13|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/.github/workflow_scripts/setup_git.sh|d2l-ai|d2l-zh|setup_git.sh|Bourne Shell|11|3|4
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/.github/workflow_scripts/utils.sh|d2l-ai|d2l-zh|utils.sh|Bourne Shell|11|7|8
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/chapter_references/zreferences.md|d2l-ai|d2l-zh|zreferences.md|Markdown|6|0|5
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/static/frontpage/attachments/sagemaker.txt|d2l-ai|d2l-zh|sagemaker.txt|Text|5|0|2
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/static/frontpage/attachments/hardcopy.txt|d2l-ai|d2l-zh|hardcopy.txt|Text|4|0|1
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/ci/docker/entry.sh|d2l-ai|d2l-zh|entry.sh|Bourne Shell|3|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/d2lzh/__init__.py|d2l-ai|d2l-zh|__init__.py|Python|3|0|1
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/ci/docker/login_ecr.sh|d2l-ai|d2l-zh|login_ecr.sh|Bourne Shell|2|0|1
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/contrib/to-rm-mx-contrib-text/d2lzh/text/__init__.py|d2l-ai|d2l-zh|__init__.py|Python|2|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/d2l/__init__.py|d2l-ai|d2l-zh|__init__.py|Python|1|7|4
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/graffle/convert.sh|d2l-ai|d2l-zh|convert.sh|Bourne Shell|1|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/flopsvsprice.svg|d2l-ai|d2l-zh|flopsvsprice.svg|SVG|1|0|0
./src/_00.1/output-0-clone/Python/d2l-ai~d2l-zh/img/wattvsprice.svg|d2l-ai|d2l-zh|wattvsprice.svg|SVG|1|0|0
